{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1758839791622,
     "user": {
      "displayName": "Oscar Zhang",
      "userId": "08884929965206842440"
     },
     "user_tz": -60
    },
    "id": "fWGYfkhF4JUm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available? True\n",
      "Device: NVIDIA A2\n",
      "Using device: cuda\n",
      "\n",
      "=== Sweep N_f = 500 (N_i=101, N_b=51, N_k=51) ===\n",
      "Epochs:      0 | TrainLoss: 1.495e+01 | Val MSE: 1.680e-01 | Max Val |err|: 9.973e-01 | Time: 4.00s\n",
      "Epochs:   5000 | TrainLoss: 4.602e-03 | Val MSE: 4.847e-06 | Max Val |err|: 6.737e-03 | Time: 16.39s\n",
      "Epochs:  10000 | TrainLoss: 1.468e-03 | Val MSE: 7.672e-07 | Max Val |err|: 2.644e-03 | Time: 15.66s\n",
      "Epochs:  15000 | TrainLoss: 6.021e-04 | Val MSE: 4.079e-07 | Max Val |err|: 2.443e-03 | Time: 15.43s\n",
      "Epochs:  20000 | TrainLoss: 7.047e-04 | Val MSE: 6.228e-07 | Max Val |err|: 2.187e-03 | Time: 15.23s\n",
      "Epochs:  25000 | TrainLoss: 3.348e-04 | Val MSE: 6.046e-07 | Max Val |err|: 3.278e-03 | Time: 15.39s\n",
      "Epochs:  30000 | TrainLoss: 1.367e-03 | Val MSE: 8.946e-06 | Max Val |err|: 5.359e-03 | Time: 15.22s\n",
      "Epochs:  35000 | TrainLoss: 1.211e-03 | Val MSE: 3.416e-06 | Max Val |err|: 4.487e-03 | Time: 15.10s\n",
      "Epochs:  40000 | TrainLoss: 1.937e-04 | Val MSE: 2.540e-07 | Max Val |err|: 2.498e-03 | Time: 15.22s\n",
      "Epochs:  45000 | TrainLoss: 1.618e-04 | Val MSE: 2.851e-07 | Max Val |err|: 2.589e-03 | Time: 15.10s\n",
      "Epochs:  50000 | TrainLoss: 2.411e-04 | Val MSE: 1.029e-06 | Max Val |err|: 2.405e-03 | Time: 15.25s\n",
      "Epochs:  55000 | TrainLoss: 2.297e-04 | Val MSE: 5.412e-07 | Max Val |err|: 1.852e-03 | Time: 15.13s\n",
      "Epochs:  60000 | TrainLoss: 1.201e-04 | Val MSE: 2.123e-07 | Max Val |err|: 2.149e-03 | Time: 15.24s\n",
      "Epochs:  65000 | TrainLoss: 1.306e-04 | Val MSE: 5.164e-07 | Max Val |err|: 2.525e-03 | Time: 15.17s\n",
      "Epochs:  70000 | TrainLoss: 2.582e-04 | Val MSE: 1.313e-06 | Max Val |err|: 2.605e-03 | Time: 15.22s\n",
      "Epochs:  75000 | TrainLoss: 1.619e-04 | Val MSE: 5.167e-07 | Max Val |err|: 1.970e-03 | Time: 15.16s\n",
      "Epochs:  80000 | TrainLoss: 2.254e-03 | Val MSE: 9.487e-06 | Max Val |err|: 5.948e-03 | Time: 15.25s\n",
      "Epochs:  85000 | TrainLoss: 8.532e-05 | Val MSE: 1.515e-07 | Max Val |err|: 1.570e-03 | Time: 15.12s\n",
      "Epochs:  90000 | TrainLoss: 2.959e-03 | Val MSE: 1.429e-05 | Max Val |err|: 7.316e-03 | Time: 15.68s\n",
      "Epochs:  95000 | TrainLoss: 5.464e-04 | Val MSE: 2.181e-06 | Max Val |err|: 3.523e-03 | Time: 15.49s\n",
      "Total training time: 310.60 s\n",
      "Best Val MSE: 1.336e-07 at epoch 99834\n",
      "Best Max |err| on validation: 1.386e-03\n",
      "\n",
      "=== Sweep N_f = 1000 (N_i=101, N_b=51, N_k=51) ===\n",
      "Epochs:      0 | TrainLoss: 2.267e+01 | Val MSE: 1.145e-01 | Max Val |err|: 8.015e-01 | Time: 0.01s\n",
      "Epochs:   5000 | TrainLoss: 3.099e-03 | Val MSE: 6.053e-06 | Max Val |err|: 1.172e-02 | Time: 29.12s\n",
      "Epochs:  10000 | TrainLoss: 2.711e-03 | Val MSE: 3.986e-05 | Max Val |err|: 1.274e-02 | Time: 17.20s\n",
      "Epochs:  15000 | TrainLoss: 6.051e-04 | Val MSE: 1.428e-06 | Max Val |err|: 5.380e-03 | Time: 16.66s\n",
      "Epochs:  20000 | TrainLoss: 4.089e-04 | Val MSE: 9.753e-07 | Max Val |err|: 4.482e-03 | Time: 17.04s\n",
      "Epochs:  25000 | TrainLoss: 5.168e-04 | Val MSE: 2.947e-06 | Max Val |err|: 3.992e-03 | Time: 16.80s\n",
      "Epochs:  30000 | TrainLoss: 1.386e-02 | Val MSE: 6.795e-05 | Max Val |err|: 1.595e-02 | Time: 16.88s\n",
      "Epochs:  35000 | TrainLoss: 6.256e-04 | Val MSE: 2.098e-06 | Max Val |err|: 4.152e-03 | Time: 16.80s\n",
      "Epochs:  40000 | TrainLoss: 2.972e-03 | Val MSE: 1.230e-05 | Max Val |err|: 1.027e-02 | Time: 16.83s\n",
      "Epochs:  45000 | TrainLoss: 7.178e-04 | Val MSE: 2.496e-06 | Max Val |err|: 4.838e-03 | Time: 16.89s\n",
      "Epochs:  50000 | TrainLoss: 1.706e-03 | Val MSE: 5.299e-06 | Max Val |err|: 4.519e-03 | Time: 16.98s\n",
      "Epochs:  55000 | TrainLoss: 9.745e-05 | Val MSE: 3.457e-07 | Max Val |err|: 2.961e-03 | Time: 16.63s\n",
      "Epochs:  60000 | TrainLoss: 8.755e-05 | Val MSE: 3.266e-07 | Max Val |err|: 3.014e-03 | Time: 16.80s\n",
      "Epochs:  65000 | TrainLoss: 1.230e-04 | Val MSE: 5.202e-07 | Max Val |err|: 2.351e-03 | Time: 16.88s\n",
      "Epochs:  70000 | TrainLoss: 1.377e-03 | Val MSE: 1.164e-05 | Max Val |err|: 5.543e-03 | Time: 16.81s\n",
      "Epochs:  75000 | TrainLoss: 1.161e-04 | Val MSE: 5.213e-07 | Max Val |err|: 2.292e-03 | Time: 17.12s\n",
      "Epochs:  80000 | TrainLoss: 6.778e-05 | Val MSE: 3.840e-07 | Max Val |err|: 2.985e-03 | Time: 17.61s\n",
      "Epochs:  85000 | TrainLoss: 8.279e-05 | Val MSE: 4.281e-07 | Max Val |err|: 3.295e-03 | Time: 17.74s\n",
      "Epochs:  90000 | TrainLoss: 2.391e-03 | Val MSE: 1.113e-05 | Max Val |err|: 6.685e-03 | Time: 17.54s\n",
      "Epochs:  95000 | TrainLoss: 6.341e-05 | Val MSE: 2.975e-07 | Max Val |err|: 2.381e-03 | Time: 17.92s\n",
      "Total training time: 354.46 s\n",
      "Best Val MSE: 2.421e-07 at epoch 99862\n",
      "Best Max |err| on validation: 2.742e-03\n",
      "\n",
      "=== Sweep N_f = 2000 (N_i=101, N_b=51, N_k=51) ===\n",
      "Epochs:      0 | TrainLoss: 1.869e+01 | Val MSE: 1.546e-01 | Max Val |err|: 9.652e-01 | Time: 0.01s\n",
      "Epochs:   5000 | TrainLoss: 7.749e-03 | Val MSE: 1.150e-05 | Max Val |err|: 1.267e-02 | Time: 18.61s\n",
      "Epochs:  10000 | TrainLoss: 2.223e-03 | Val MSE: 2.337e-06 | Max Val |err|: 5.495e-03 | Time: 17.87s\n",
      "Epochs:  15000 | TrainLoss: 7.585e-04 | Val MSE: 8.385e-07 | Max Val |err|: 3.742e-03 | Time: 17.45s\n",
      "Epochs:  20000 | TrainLoss: 4.617e-03 | Val MSE: 5.655e-06 | Max Val |err|: 5.769e-03 | Time: 17.52s\n",
      "Epochs:  25000 | TrainLoss: 4.773e-04 | Val MSE: 1.114e-06 | Max Val |err|: 3.401e-03 | Time: 17.37s\n",
      "Epochs:  30000 | TrainLoss: 3.184e-04 | Val MSE: 6.007e-07 | Max Val |err|: 2.925e-03 | Time: 17.37s\n",
      "Epochs:  35000 | TrainLoss: 2.521e-04 | Val MSE: 2.922e-07 | Max Val |err|: 2.154e-03 | Time: 17.29s\n",
      "Epochs:  40000 | TrainLoss: 6.199e-04 | Val MSE: 1.456e-06 | Max Val |err|: 2.707e-03 | Time: 17.32s\n",
      "Epochs:  45000 | TrainLoss: 8.079e-04 | Val MSE: 7.713e-07 | Max Val |err|: 2.415e-03 | Time: 17.25s\n",
      "Epochs:  50000 | TrainLoss: 1.583e-04 | Val MSE: 1.503e-07 | Max Val |err|: 1.818e-03 | Time: 17.38s\n",
      "Epochs:  55000 | TrainLoss: 5.476e-04 | Val MSE: 8.264e-06 | Max Val |err|: 4.995e-03 | Time: 17.26s\n",
      "Epochs:  60000 | TrainLoss: 4.606e-04 | Val MSE: 9.382e-07 | Max Val |err|: 3.617e-03 | Time: 17.33s\n",
      "Epochs:  65000 | TrainLoss: 8.825e-04 | Val MSE: 3.287e-06 | Max Val |err|: 4.923e-03 | Time: 17.26s\n",
      "Epochs:  70000 | TrainLoss: 1.442e-03 | Val MSE: 7.117e-06 | Max Val |err|: 4.769e-03 | Time: 17.35s\n",
      "Epochs:  75000 | TrainLoss: 9.858e-05 | Val MSE: 9.529e-08 | Max Val |err|: 1.307e-03 | Time: 17.26s\n",
      "Epochs:  80000 | TrainLoss: 1.494e-04 | Val MSE: 2.243e-07 | Max Val |err|: 1.511e-03 | Time: 17.31s\n",
      "Epochs:  85000 | TrainLoss: 8.881e-05 | Val MSE: 3.743e-07 | Max Val |err|: 1.458e-03 | Time: 17.28s\n",
      "Epochs:  90000 | TrainLoss: 7.084e-04 | Val MSE: 3.106e-06 | Max Val |err|: 3.128e-03 | Time: 17.31s\n",
      "Epochs:  95000 | TrainLoss: 1.207e-04 | Val MSE: 1.094e-07 | Max Val |err|: 1.211e-03 | Time: 17.28s\n",
      "Total training time: 348.41 s\n",
      "Best Val MSE: 5.999e-08 at epoch 99995\n",
      "Best Max |err| on validation: 9.022e-04\n",
      "\n",
      "=== Sweep N_f = 4000 (N_i=101, N_b=51, N_k=51) ===\n",
      "Epochs:      0 | TrainLoss: 1.924e+01 | Val MSE: 1.361e-01 | Max Val |err|: 6.762e-01 | Time: 0.01s\n",
      "Epochs:   5000 | TrainLoss: 2.701e-03 | Val MSE: 3.482e-06 | Max Val |err|: 8.810e-03 | Time: 22.96s\n",
      "Epochs:  10000 | TrainLoss: 7.377e-04 | Val MSE: 1.397e-06 | Max Val |err|: 4.705e-03 | Time: 22.50s\n",
      "Epochs:  15000 | TrainLoss: 4.494e-04 | Val MSE: 9.055e-07 | Max Val |err|: 3.643e-03 | Time: 22.56s\n",
      "Epochs:  20000 | TrainLoss: 4.114e-03 | Val MSE: 2.157e-05 | Max Val |err|: 1.197e-02 | Time: 22.15s\n",
      "Epochs:  25000 | TrainLoss: 2.914e-04 | Val MSE: 5.789e-07 | Max Val |err|: 3.112e-03 | Time: 22.01s\n",
      "Epochs:  30000 | TrainLoss: 2.248e-04 | Val MSE: 3.402e-07 | Max Val |err|: 2.206e-03 | Time: 21.82s\n",
      "Epochs:  35000 | TrainLoss: 4.638e-04 | Val MSE: 1.042e-06 | Max Val |err|: 3.184e-03 | Time: 22.04s\n",
      "Epochs:  40000 | TrainLoss: 1.515e-04 | Val MSE: 2.104e-07 | Max Val |err|: 1.813e-03 | Time: 22.13s\n",
      "Epochs:  45000 | TrainLoss: 5.662e-04 | Val MSE: 5.622e-06 | Max Val |err|: 5.003e-03 | Time: 22.97s\n",
      "Epochs:  50000 | TrainLoss: 1.195e-04 | Val MSE: 2.293e-07 | Max Val |err|: 1.717e-03 | Time: 22.37s\n",
      "Epochs:  55000 | TrainLoss: 6.653e-04 | Val MSE: 2.074e-06 | Max Val |err|: 2.718e-03 | Time: 22.66s\n",
      "Epochs:  60000 | TrainLoss: 9.266e-05 | Val MSE: 1.093e-07 | Max Val |err|: 1.265e-03 | Time: 22.00s\n",
      "Epochs:  65000 | TrainLoss: 7.959e-05 | Val MSE: 1.056e-07 | Max Val |err|: 1.201e-03 | Time: 21.80s\n",
      "Epochs:  70000 | TrainLoss: 1.760e-04 | Val MSE: 1.226e-06 | Max Val |err|: 1.798e-03 | Time: 20.63s\n",
      "Epochs:  75000 | TrainLoss: 6.644e-05 | Val MSE: 9.853e-08 | Max Val |err|: 1.026e-03 | Time: 20.54s\n",
      "Epochs:  80000 | TrainLoss: 5.909e-05 | Val MSE: 6.767e-08 | Max Val |err|: 1.018e-03 | Time: 19.97s\n",
      "Epochs:  85000 | TrainLoss: 5.864e-05 | Val MSE: 1.273e-07 | Max Val |err|: 1.198e-03 | Time: 19.99s\n",
      "Epochs:  90000 | TrainLoss: 5.291e-05 | Val MSE: 8.036e-08 | Max Val |err|: 9.994e-04 | Time: 19.96s\n",
      "Epochs:  95000 | TrainLoss: 5.054e-05 | Val MSE: 6.967e-08 | Max Val |err|: 9.516e-04 | Time: 19.89s\n",
      "Total training time: 430.94 s\n",
      "Best Val MSE: 4.694e-08 at epoch 99992\n",
      "Best Max |err| on validation: 8.685e-04\n",
      "\n",
      "N_f sweep summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_i</th>\n",
       "      <th>N_b</th>\n",
       "      <th>N_k</th>\n",
       "      <th>N_f</th>\n",
       "      <th>total_elapsed</th>\n",
       "      <th>best_ep</th>\n",
       "      <th>best_TL</th>\n",
       "      <th>best_v</th>\n",
       "      <th>best_max_err</th>\n",
       "      <th>rel_L2</th>\n",
       "      <th>loss_values</th>\n",
       "      <th>mse_v_hist</th>\n",
       "      <th>max_errors</th>\n",
       "      <th>training_curve_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>500</td>\n",
       "      <td>325.788458</td>\n",
       "      <td>99834</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>1.336201e-07</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>[14.947761535644531, 14.056835174560547, 13.30...</td>\n",
       "      <td>[(0, 0.16799819469451904), (1, 0.1549804210662...</td>\n",
       "      <td>[(0, 0.9973016381263733), (1, 0.95520174503326...</td>\n",
       "      <td>sweep_Nf/train_Ni101_Nb51_Nk51_Nf500.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>354.457757</td>\n",
       "      <td>99862</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2.421271e-07</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>[22.66531753540039, 18.658302307128906, 15.583...</td>\n",
       "      <td>[(0, 0.11447107046842575), (1, 0.0983603522181...</td>\n",
       "      <td>[(0, 0.8015083074569702), (1, 0.77515494823455...</td>\n",
       "      <td>sweep_Nf/train_Ni101_Nb51_Nk51_Nf1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>2000</td>\n",
       "      <td>348.416040</td>\n",
       "      <td>99995</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>5.998968e-08</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>[18.694698333740234, 15.184746742248535, 12.93...</td>\n",
       "      <td>[(0, 0.15464738011360168), (1, 0.1395625472068...</td>\n",
       "      <td>[(0, 0.9652208089828491), (1, 0.93920427560806...</td>\n",
       "      <td>sweep_Nf/train_Ni101_Nb51_Nk51_Nf2000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>4000</td>\n",
       "      <td>430.942955</td>\n",
       "      <td>99992</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>4.694115e-08</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>[19.242321014404297, 16.772865295410156, 14.82...</td>\n",
       "      <td>[(0, 0.13613589107990265), (1, 0.1285412907600...</td>\n",
       "      <td>[(0, 0.6762097477912903), (1, 0.69359844923019...</td>\n",
       "      <td>sweep_Nf/train_Ni101_Nb51_Nk51_Nf4000.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   N_i  N_b  N_k   N_f  total_elapsed  best_ep   best_TL        best_v  \\\n",
       "0  101   51   51   500     325.788458    99834  0.000074  1.336201e-07   \n",
       "1  101   51   51  1000     354.457757    99862  0.000050  2.421271e-07   \n",
       "2  101   51   51  2000     348.416040    99995  0.000067  5.998968e-08   \n",
       "3  101   51   51  4000     430.942955    99992  0.000044  4.694115e-08   \n",
       "\n",
       "   best_max_err    rel_L2                                        loss_values  \\\n",
       "0      0.001386  0.000723  [14.947761535644531, 14.056835174560547, 13.30...   \n",
       "1      0.002742  0.000775  [22.66531753540039, 18.658302307128906, 15.583...   \n",
       "2      0.000902  0.000610  [18.694698333740234, 15.184746742248535, 12.93...   \n",
       "3      0.000869  0.000558  [19.242321014404297, 16.772865295410156, 14.82...   \n",
       "\n",
       "                                          mse_v_hist  \\\n",
       "0  [(0, 0.16799819469451904), (1, 0.1549804210662...   \n",
       "1  [(0, 0.11447107046842575), (1, 0.0983603522181...   \n",
       "2  [(0, 0.15464738011360168), (1, 0.1395625472068...   \n",
       "3  [(0, 0.13613589107990265), (1, 0.1285412907600...   \n",
       "\n",
       "                                          max_errors  \\\n",
       "0  [(0, 0.9973016381263733), (1, 0.95520174503326...   \n",
       "1  [(0, 0.8015083074569702), (1, 0.77515494823455...   \n",
       "2  [(0, 0.9652208089828491), (1, 0.93920427560806...   \n",
       "3  [(0, 0.6762097477912903), (1, 0.69359844923019...   \n",
       "\n",
       "                         training_curve_path  \n",
       "0   sweep_Nf/train_Ni101_Nb51_Nk51_Nf500.png  \n",
       "1  sweep_Nf/train_Ni101_Nb51_Nk51_Nf1000.png  \n",
       "2  sweep_Nf/train_Ni101_Nb51_Nk51_Nf2000.png  \n",
       "3  sweep_Nf/train_Ni101_Nb51_Nk51_Nf4000.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sweep N_i = 21 (N_b=51, N_k=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 3.195e+01 | Val MSE: 2.088e-01 | Max Val |err|: 1.116e+00 | Time: 0.00s\n",
      "Epochs:   5000 | TrainLoss: 4.133e-03 | Val MSE: 8.004e-06 | Max Val |err|: 7.970e-03 | Time: 16.02s\n",
      "Epochs:  10000 | TrainLoss: 1.664e-03 | Val MSE: 4.840e-06 | Max Val |err|: 6.313e-03 | Time: 15.35s\n",
      "Epochs:  15000 | TrainLoss: 6.792e-04 | Val MSE: 2.441e-06 | Max Val |err|: 4.060e-03 | Time: 14.91s\n",
      "Epochs:  20000 | TrainLoss: 3.861e-04 | Val MSE: 5.122e-07 | Max Val |err|: 2.911e-03 | Time: 14.95s\n",
      "Epochs:  25000 | TrainLoss: 2.886e-04 | Val MSE: 4.254e-07 | Max Val |err|: 2.095e-03 | Time: 15.10s\n",
      "Epochs:  30000 | TrainLoss: 2.532e-04 | Val MSE: 5.089e-07 | Max Val |err|: 2.321e-03 | Time: 14.96s\n",
      "Epochs:  35000 | TrainLoss: 3.319e-04 | Val MSE: 2.535e-06 | Max Val |err|: 3.432e-03 | Time: 16.01s\n",
      "Epochs:  40000 | TrainLoss: 2.300e-04 | Val MSE: 4.570e-07 | Max Val |err|: 1.850e-03 | Time: 14.72s\n",
      "Epochs:  45000 | TrainLoss: 5.845e-04 | Val MSE: 4.407e-06 | Max Val |err|: 3.261e-03 | Time: 15.21s\n",
      "Epochs:  50000 | TrainLoss: 1.286e-04 | Val MSE: 2.671e-07 | Max Val |err|: 1.457e-03 | Time: 14.64s\n",
      "Epochs:  55000 | TrainLoss: 1.182e-04 | Val MSE: 3.512e-07 | Max Val |err|: 1.547e-03 | Time: 15.37s\n",
      "Epochs:  60000 | TrainLoss: 1.923e-04 | Val MSE: 5.093e-07 | Max Val |err|: 1.664e-03 | Time: 15.32s\n",
      "Epochs:  65000 | TrainLoss: 8.959e-05 | Val MSE: 2.145e-07 | Max Val |err|: 1.586e-03 | Time: 15.61s\n",
      "Epochs:  70000 | TrainLoss: 4.003e-04 | Val MSE: 3.961e-06 | Max Val |err|: 2.872e-03 | Time: 14.86s\n",
      "Epochs:  75000 | TrainLoss: 9.827e-05 | Val MSE: 3.337e-07 | Max Val |err|: 1.640e-03 | Time: 14.98s\n",
      "Epochs:  80000 | TrainLoss: 1.694e-03 | Val MSE: 1.787e-05 | Max Val |err|: 5.631e-03 | Time: 14.84s\n",
      "Epochs:  85000 | TrainLoss: 3.223e-03 | Val MSE: 3.882e-05 | Max Val |err|: 9.778e-03 | Time: 14.95s\n",
      "Epochs:  90000 | TrainLoss: 7.819e-05 | Val MSE: 2.022e-07 | Max Val |err|: 1.480e-03 | Time: 15.10s\n",
      "Epochs:  95000 | TrainLoss: 5.341e-05 | Val MSE: 1.268e-07 | Max Val |err|: 1.014e-03 | Time: 14.82s\n",
      "Total training time: 303.03 s\n",
      "Best Val MSE: 9.675e-08 at epoch 99931\n",
      "Best Max |err| on validation: 1.159e-03\n",
      "\n",
      "=== Sweep N_i = 51 (N_b=51, N_k=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 1.874e+01 | Val MSE: 1.527e-01 | Max Val |err|: 9.354e-01 | Time: 0.00s\n",
      "Epochs:   5000 | TrainLoss: 1.707e-03 | Val MSE: 3.667e-06 | Max Val |err|: 7.370e-03 | Time: 16.02s\n",
      "Epochs:  10000 | TrainLoss: 6.126e-04 | Val MSE: 1.189e-06 | Max Val |err|: 4.428e-03 | Time: 15.62s\n",
      "Epochs:  15000 | TrainLoss: 1.740e-03 | Val MSE: 7.132e-06 | Max Val |err|: 7.068e-03 | Time: 15.25s\n",
      "Epochs:  20000 | TrainLoss: 5.826e-04 | Val MSE: 5.924e-06 | Max Val |err|: 6.175e-03 | Time: 15.65s\n",
      "Epochs:  25000 | TrainLoss: 1.799e-04 | Val MSE: 4.440e-07 | Max Val |err|: 3.235e-03 | Time: 15.42s\n",
      "Epochs:  30000 | TrainLoss: 7.130e-04 | Val MSE: 2.372e-06 | Max Val |err|: 3.918e-03 | Time: 15.33s\n",
      "Epochs:  35000 | TrainLoss: 2.471e-04 | Val MSE: 1.179e-06 | Max Val |err|: 2.825e-03 | Time: 15.47s\n",
      "Epochs:  40000 | TrainLoss: 1.089e-03 | Val MSE: 5.399e-06 | Max Val |err|: 4.793e-03 | Time: 15.23s\n",
      "Epochs:  45000 | TrainLoss: 1.280e-04 | Val MSE: 2.648e-07 | Max Val |err|: 2.490e-03 | Time: 15.21s\n",
      "Epochs:  50000 | TrainLoss: 1.190e-04 | Val MSE: 2.532e-07 | Max Val |err|: 2.716e-03 | Time: 15.54s\n",
      "Epochs:  55000 | TrainLoss: 5.062e-04 | Val MSE: 7.222e-06 | Max Val |err|: 5.003e-03 | Time: 15.48s\n",
      "Epochs:  60000 | TrainLoss: 1.132e-04 | Val MSE: 8.557e-07 | Max Val |err|: 2.245e-03 | Time: 15.32s\n",
      "Epochs:  65000 | TrainLoss: 6.853e-05 | Val MSE: 2.312e-07 | Max Val |err|: 2.067e-03 | Time: 15.29s\n",
      "Epochs:  70000 | TrainLoss: 5.589e-05 | Val MSE: 1.074e-07 | Max Val |err|: 1.587e-03 | Time: 15.46s\n",
      "Epochs:  75000 | TrainLoss: 5.993e-05 | Val MSE: 1.884e-07 | Max Val |err|: 1.992e-03 | Time: 15.88s\n",
      "Epochs:  80000 | TrainLoss: 8.787e-05 | Val MSE: 6.315e-07 | Max Val |err|: 1.441e-03 | Time: 15.35s\n",
      "Epochs:  85000 | TrainLoss: 1.550e-04 | Val MSE: 8.522e-07 | Max Val |err|: 1.979e-03 | Time: 15.13s\n",
      "Epochs:  90000 | TrainLoss: 3.999e-05 | Val MSE: 8.531e-08 | Max Val |err|: 1.539e-03 | Time: 15.05s\n",
      "Epochs:  95000 | TrainLoss: 4.091e-05 | Val MSE: 7.951e-08 | Max Val |err|: 1.414e-03 | Time: 14.98s\n",
      "Total training time: 307.75 s\n",
      "Best Val MSE: 6.673e-08 at epoch 99643\n",
      "Best Max |err| on validation: 1.310e-03\n",
      "\n",
      "=== Sweep N_i = 101 (N_b=51, N_k=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 2.347e+01 | Val MSE: 1.284e-01 | Max Val |err|: 8.848e-01 | Time: 0.00s\n",
      "Epochs:   5000 | TrainLoss: 3.269e-03 | Val MSE: 5.791e-06 | Max Val |err|: 1.041e-02 | Time: 16.44s\n",
      "Epochs:  10000 | TrainLoss: 1.004e-03 | Val MSE: 2.150e-06 | Max Val |err|: 6.353e-03 | Time: 15.91s\n",
      "Epochs:  15000 | TrainLoss: 5.805e-04 | Val MSE: 1.265e-06 | Max Val |err|: 5.267e-03 | Time: 15.55s\n",
      "Epochs:  20000 | TrainLoss: 4.073e-04 | Val MSE: 8.159e-07 | Max Val |err|: 4.454e-03 | Time: 15.54s\n",
      "Epochs:  25000 | TrainLoss: 1.221e-03 | Val MSE: 6.058e-06 | Max Val |err|: 8.018e-03 | Time: 15.62s\n",
      "Epochs:  30000 | TrainLoss: 3.317e-04 | Val MSE: 1.043e-06 | Max Val |err|: 4.451e-03 | Time: 15.80s\n",
      "Epochs:  35000 | TrainLoss: 2.097e-04 | Val MSE: 3.568e-06 | Max Val |err|: 5.746e-03 | Time: 15.76s\n",
      "Epochs:  40000 | TrainLoss: 4.048e-04 | Val MSE: 3.562e-06 | Max Val |err|: 3.231e-03 | Time: 15.88s\n",
      "Epochs:  45000 | TrainLoss: 2.106e-04 | Val MSE: 6.155e-07 | Max Val |err|: 3.202e-03 | Time: 15.55s\n",
      "Epochs:  50000 | TrainLoss: 1.359e-04 | Val MSE: 3.111e-07 | Max Val |err|: 2.917e-03 | Time: 15.66s\n",
      "Epochs:  55000 | TrainLoss: 1.078e-04 | Val MSE: 2.375e-07 | Max Val |err|: 2.533e-03 | Time: 15.66s\n",
      "Epochs:  60000 | TrainLoss: 1.177e-04 | Val MSE: 2.689e-07 | Max Val |err|: 2.631e-03 | Time: 15.62s\n",
      "Epochs:  65000 | TrainLoss: 4.430e-04 | Val MSE: 2.392e-06 | Max Val |err|: 3.110e-03 | Time: 15.42s\n",
      "Epochs:  70000 | TrainLoss: 1.190e-04 | Val MSE: 5.788e-07 | Max Val |err|: 1.810e-03 | Time: 15.60s\n",
      "Epochs:  75000 | TrainLoss: 6.749e-05 | Val MSE: 1.748e-07 | Max Val |err|: 2.307e-03 | Time: 15.57s\n",
      "Epochs:  80000 | TrainLoss: 1.853e-04 | Val MSE: 6.340e-07 | Max Val |err|: 1.651e-03 | Time: 15.45s\n",
      "Epochs:  85000 | TrainLoss: 6.977e-04 | Val MSE: 4.700e-07 | Max Val |err|: 2.831e-03 | Time: 15.52s\n",
      "Epochs:  90000 | TrainLoss: 8.165e-05 | Val MSE: 2.230e-07 | Max Val |err|: 2.264e-03 | Time: 15.44s\n",
      "Epochs:  95000 | TrainLoss: 4.835e-05 | Val MSE: 1.238e-07 | Max Val |err|: 1.881e-03 | Time: 15.57s\n",
      "Total training time: 312.96 s\n",
      "Best Val MSE: 1.102e-07 at epoch 99872\n",
      "Best Max |err| on validation: 1.748e-03\n",
      "\n",
      "=== Sweep N_i = 201 (N_b=51, N_k=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 2.967e+01 | Val MSE: 1.158e-01 | Max Val |err|: 9.208e-01 | Time: 0.00s\n",
      "Epochs:   5000 | TrainLoss: 1.716e-02 | Val MSE: 5.642e-05 | Max Val |err|: 2.186e-02 | Time: 17.83s\n",
      "Epochs:  10000 | TrainLoss: 9.934e-04 | Val MSE: 2.812e-06 | Max Val |err|: 7.770e-03 | Time: 16.91s\n",
      "Epochs:  15000 | TrainLoss: 4.797e-03 | Val MSE: 1.622e-05 | Max Val |err|: 8.418e-03 | Time: 16.93s\n",
      "Epochs:  20000 | TrainLoss: 4.455e-04 | Val MSE: 1.348e-06 | Max Val |err|: 5.656e-03 | Time: 16.95s\n",
      "Epochs:  25000 | TrainLoss: 2.907e-04 | Val MSE: 1.075e-06 | Max Val |err|: 5.444e-03 | Time: 16.76s\n",
      "Epochs:  30000 | TrainLoss: 3.176e-04 | Val MSE: 3.942e-06 | Max Val |err|: 5.891e-03 | Time: 16.68s\n",
      "Epochs:  35000 | TrainLoss: 1.869e-04 | Val MSE: 8.831e-07 | Max Val |err|: 4.723e-03 | Time: 16.79s\n",
      "Epochs:  40000 | TrainLoss: 7.583e-04 | Val MSE: 5.285e-06 | Max Val |err|: 6.440e-03 | Time: 16.96s\n",
      "Epochs:  45000 | TrainLoss: 1.376e-03 | Val MSE: 7.242e-06 | Max Val |err|: 6.921e-03 | Time: 17.13s\n",
      "Epochs:  50000 | TrainLoss: 1.948e-04 | Val MSE: 5.817e-07 | Max Val |err|: 2.455e-03 | Time: 16.90s\n",
      "Epochs:  55000 | TrainLoss: 1.554e-03 | Val MSE: 2.092e-05 | Max Val |err|: 7.054e-03 | Time: 16.77s\n",
      "Epochs:  60000 | TrainLoss: 1.740e-03 | Val MSE: 3.058e-06 | Max Val |err|: 2.623e-03 | Time: 16.83s\n",
      "Epochs:  65000 | TrainLoss: 1.909e-03 | Val MSE: 5.002e-06 | Max Val |err|: 3.843e-03 | Time: 16.78s\n",
      "Epochs:  70000 | TrainLoss: 3.532e-04 | Val MSE: 3.030e-06 | Max Val |err|: 4.047e-03 | Time: 16.50s\n",
      "Epochs:  75000 | TrainLoss: 2.997e-04 | Val MSE: 1.814e-06 | Max Val |err|: 2.340e-03 | Time: 16.75s\n",
      "Epochs:  80000 | TrainLoss: 5.419e-03 | Val MSE: 2.594e-05 | Max Val |err|: 8.469e-03 | Time: 33.76s\n",
      "Epochs:  85000 | TrainLoss: 6.667e-04 | Val MSE: 7.676e-06 | Max Val |err|: 4.705e-03 | Time: 20.90s\n",
      "Epochs:  90000 | TrainLoss: 4.200e-03 | Val MSE: 4.655e-05 | Max Val |err|: 1.217e-02 | Time: 17.45s\n",
      "Epochs:  95000 | TrainLoss: 4.865e-03 | Val MSE: 9.659e-06 | Max Val |err|: 8.409e-03 | Time: 17.13s\n",
      "Total training time: 359.87 s\n",
      "Best Val MSE: 1.639e-07 at epoch 99885\n",
      "Best Max |err| on validation: 2.081e-03\n",
      "\n",
      "N_i sweep summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_i</th>\n",
       "      <th>N_b</th>\n",
       "      <th>N_k</th>\n",
       "      <th>N_f</th>\n",
       "      <th>total_elapsed</th>\n",
       "      <th>best_ep</th>\n",
       "      <th>best_TL</th>\n",
       "      <th>best_v</th>\n",
       "      <th>best_max_err</th>\n",
       "      <th>rel_L2</th>\n",
       "      <th>loss_values</th>\n",
       "      <th>mse_v_hist</th>\n",
       "      <th>max_errors</th>\n",
       "      <th>training_curve_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>303.029927</td>\n",
       "      <td>99931</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>9.675382e-08</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>[31.947650909423828, 26.775436401367188, 22.19...</td>\n",
       "      <td>[(0, 0.2087847888469696), (1, 0.18390968441963...</td>\n",
       "      <td>[(0, 1.1162387132644653), (1, 1.07166874408721...</td>\n",
       "      <td>sweep_Ni/train_Ni21_Nb51_Nk51_Nf1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>307.747723</td>\n",
       "      <td>99643</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>6.672719e-08</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>[18.742252349853516, 15.543389320373535, 13.08...</td>\n",
       "      <td>[(0, 0.15273211896419525), (1, 0.1351156979799...</td>\n",
       "      <td>[(0, 0.9353998303413391), (1, 0.87457603216171...</td>\n",
       "      <td>sweep_Ni/train_Ni51_Nb51_Nk51_Nf1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>312.963876</td>\n",
       "      <td>99872</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1.102093e-07</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>[23.467952728271484, 19.485658645629883, 16.33...</td>\n",
       "      <td>[(0, 0.12841792404651642), (1, 0.1118596345186...</td>\n",
       "      <td>[(0, 0.8848451972007751), (1, 0.83105754852294...</td>\n",
       "      <td>sweep_Ni/train_Ni101_Nb51_Nk51_Nf1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>359.869567</td>\n",
       "      <td>99885</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.639440e-07</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>[29.66835594177246, 24.679580688476562, 20.844...</td>\n",
       "      <td>[(0, 0.11580260843038559), (1, 0.1047088503837...</td>\n",
       "      <td>[(0, 0.9207725524902344), (1, 0.84888905286788...</td>\n",
       "      <td>sweep_Ni/train_Ni201_Nb51_Nk51_Nf1000.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   N_i  N_b  N_k   N_f  total_elapsed  best_ep   best_TL        best_v  \\\n",
       "0   21   51   51  1000     303.029927    99931  0.000047  9.675382e-08   \n",
       "1   51   51   51  1000     307.747723    99643  0.000034  6.672719e-08   \n",
       "2  101   51   51  1000     312.963876    99872  0.000044  1.102093e-07   \n",
       "3  201   51   51  1000     359.869567    99885  0.000050  1.639440e-07   \n",
       "\n",
       "   best_max_err    rel_L2                                        loss_values  \\\n",
       "0      0.001159  0.000620  [31.947650909423828, 26.775436401367188, 22.19...   \n",
       "1      0.001310  0.000470  [18.742252349853516, 15.543389320373535, 13.08...   \n",
       "2      0.001748  0.000622  [23.467952728271484, 19.485658645629883, 16.33...   \n",
       "3      0.002081  0.000535  [29.66835594177246, 24.679580688476562, 20.844...   \n",
       "\n",
       "                                          mse_v_hist  \\\n",
       "0  [(0, 0.2087847888469696), (1, 0.18390968441963...   \n",
       "1  [(0, 0.15273211896419525), (1, 0.1351156979799...   \n",
       "2  [(0, 0.12841792404651642), (1, 0.1118596345186...   \n",
       "3  [(0, 0.11580260843038559), (1, 0.1047088503837...   \n",
       "\n",
       "                                          max_errors  \\\n",
       "0  [(0, 1.1162387132644653), (1, 1.07166874408721...   \n",
       "1  [(0, 0.9353998303413391), (1, 0.87457603216171...   \n",
       "2  [(0, 0.8848451972007751), (1, 0.83105754852294...   \n",
       "3  [(0, 0.9207725524902344), (1, 0.84888905286788...   \n",
       "\n",
       "                         training_curve_path  \n",
       "0   sweep_Ni/train_Ni21_Nb51_Nk51_Nf1000.png  \n",
       "1   sweep_Ni/train_Ni51_Nb51_Nk51_Nf1000.png  \n",
       "2  sweep_Ni/train_Ni101_Nb51_Nk51_Nf1000.png  \n",
       "3  sweep_Ni/train_Ni201_Nb51_Nk51_Nf1000.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sweep N_b = 11 (N_i=101, N_k=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 3.549e+01 | Val MSE: 1.890e-01 | Max Val |err|: 7.980e-01 | Time: 0.01s\n",
      "Epochs:   5000 | TrainLoss: 2.984e-02 | Val MSE: 4.766e-05 | Max Val |err|: 2.146e-02 | Time: 31.94s\n",
      "Epochs:  10000 | TrainLoss: 1.118e-02 | Val MSE: 1.621e-05 | Max Val |err|: 1.530e-02 | Time: 31.66s\n",
      "Epochs:  15000 | TrainLoss: 6.212e-03 | Val MSE: 8.647e-06 | Max Val |err|: 1.230e-02 | Time: 31.21s\n",
      "Epochs:  20000 | TrainLoss: 3.680e-03 | Val MSE: 4.769e-06 | Max Val |err|: 9.313e-03 | Time: 30.47s\n",
      "Epochs:  25000 | TrainLoss: 2.986e-03 | Val MSE: 1.070e-05 | Max Val |err|: 1.183e-02 | Time: 30.67s\n",
      "Epochs:  30000 | TrainLoss: 1.105e-02 | Val MSE: 4.369e-06 | Max Val |err|: 9.423e-03 | Time: 30.85s\n",
      "Epochs:  35000 | TrainLoss: 9.386e-04 | Val MSE: 1.416e-06 | Max Val |err|: 6.274e-03 | Time: 29.70s\n",
      "Epochs:  40000 | TrainLoss: 6.587e-04 | Val MSE: 1.074e-06 | Max Val |err|: 5.478e-03 | Time: 30.36s\n",
      "Epochs:  45000 | TrainLoss: 6.289e-02 | Val MSE: 8.585e-05 | Max Val |err|: 2.229e-02 | Time: 30.35s\n",
      "Epochs:  50000 | TrainLoss: 3.832e-04 | Val MSE: 7.679e-07 | Max Val |err|: 4.428e-03 | Time: 29.96s\n",
      "Epochs:  55000 | TrainLoss: 1.952e-03 | Val MSE: 2.000e-06 | Max Val |err|: 4.346e-03 | Time: 29.69s\n",
      "Epochs:  60000 | TrainLoss: 2.443e-04 | Val MSE: 5.490e-07 | Max Val |err|: 3.901e-03 | Time: 29.19s\n",
      "Epochs:  65000 | TrainLoss: 2.060e-04 | Val MSE: 5.035e-07 | Max Val |err|: 3.777e-03 | Time: 29.64s\n",
      "Epochs:  70000 | TrainLoss: 2.875e-03 | Val MSE: 1.210e-05 | Max Val |err|: 8.569e-03 | Time: 29.34s\n",
      "Epochs:  75000 | TrainLoss: 2.058e-04 | Val MSE: 4.611e-07 | Max Val |err|: 3.536e-03 | Time: 29.39s\n",
      "Epochs:  80000 | TrainLoss: 2.610e-04 | Val MSE: 3.266e-06 | Max Val |err|: 3.625e-03 | Time: 29.22s\n",
      "Epochs:  85000 | TrainLoss: 1.208e-04 | Val MSE: 3.542e-07 | Max Val |err|: 2.997e-03 | Time: 29.77s\n",
      "Epochs:  90000 | TrainLoss: 1.063e-04 | Val MSE: 3.109e-07 | Max Val |err|: 2.716e-03 | Time: 30.81s\n",
      "Epochs:  95000 | TrainLoss: 9.521e-05 | Val MSE: 2.768e-07 | Max Val |err|: 2.428e-03 | Time: 29.20s\n",
      "Total training time: 603.23 s\n",
      "Best Val MSE: 2.450e-07 at epoch 99726\n",
      "Best Max |err| on validation: 2.273e-03\n",
      "\n",
      "=== Sweep N_b = 21 (N_i=101, N_k=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 4.446e+01 | Val MSE: 1.333e-01 | Max Val |err|: 1.049e+00 | Time: 0.01s\n",
      "Epochs:   5000 | TrainLoss: 2.285e-03 | Val MSE: 6.864e-06 | Max Val |err|: 8.155e-03 | Time: 34.23s\n",
      "Epochs:  10000 | TrainLoss: 6.935e-04 | Val MSE: 1.541e-06 | Max Val |err|: 3.988e-03 | Time: 32.15s\n",
      "Epochs:  15000 | TrainLoss: 3.433e-04 | Val MSE: 7.229e-07 | Max Val |err|: 3.262e-03 | Time: 31.24s\n",
      "Epochs:  20000 | TrainLoss: 2.173e-04 | Val MSE: 4.622e-07 | Max Val |err|: 2.682e-03 | Time: 30.47s\n",
      "Epochs:  25000 | TrainLoss: 1.592e-04 | Val MSE: 3.504e-07 | Max Val |err|: 2.287e-03 | Time: 30.09s\n",
      "Epochs:  30000 | TrainLoss: 1.245e-04 | Val MSE: 2.873e-07 | Max Val |err|: 1.999e-03 | Time: 29.87s\n",
      "Epochs:  35000 | TrainLoss: 1.443e-04 | Val MSE: 1.479e-06 | Max Val |err|: 3.708e-03 | Time: 29.28s\n",
      "Epochs:  40000 | TrainLoss: 8.955e-05 | Val MSE: 3.710e-07 | Max Val |err|: 1.800e-03 | Time: 28.81s\n",
      "Epochs:  45000 | TrainLoss: 2.029e-04 | Val MSE: 4.547e-07 | Max Val |err|: 1.886e-03 | Time: 29.26s\n",
      "Epochs:  50000 | TrainLoss: 9.607e-05 | Val MSE: 2.662e-07 | Max Val |err|: 1.454e-03 | Time: 29.69s\n",
      "Epochs:  55000 | TrainLoss: 1.647e-04 | Val MSE: 2.350e-07 | Max Val |err|: 1.586e-03 | Time: 28.91s\n",
      "Epochs:  60000 | TrainLoss: 9.413e-03 | Val MSE: 3.431e-05 | Max Val |err|: 1.108e-02 | Time: 29.15s\n",
      "Epochs:  65000 | TrainLoss: 7.101e-05 | Val MSE: 4.582e-07 | Max Val |err|: 1.307e-03 | Time: 29.69s\n",
      "Epochs:  70000 | TrainLoss: 3.700e-04 | Val MSE: 3.984e-06 | Max Val |err|: 3.818e-03 | Time: 29.32s\n",
      "Epochs:  75000 | TrainLoss: 5.501e-05 | Val MSE: 1.747e-07 | Max Val |err|: 1.488e-03 | Time: 29.15s\n",
      "Epochs:  80000 | TrainLoss: 3.004e-04 | Val MSE: 1.064e-06 | Max Val |err|: 3.277e-03 | Time: 28.94s\n",
      "Epochs:  85000 | TrainLoss: 1.459e-04 | Val MSE: 1.102e-06 | Max Val |err|: 2.564e-03 | Time: 29.07s\n",
      "Epochs:  90000 | TrainLoss: 2.460e-04 | Val MSE: 1.957e-06 | Max Val |err|: 3.276e-03 | Time: 28.46s\n",
      "Epochs:  95000 | TrainLoss: 3.738e-05 | Val MSE: 9.503e-08 | Max Val |err|: 1.163e-03 | Time: 28.52s\n",
      "Total training time: 595.70 s\n",
      "Best Val MSE: 8.869e-08 at epoch 99960\n",
      "Best Max |err| on validation: 1.138e-03\n",
      "\n",
      "=== Sweep N_b = 51 (N_i=101, N_k=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 4.469e+01 | Val MSE: 1.693e-01 | Max Val |err|: 1.065e+00 | Time: 0.01s\n",
      "Epochs:   5000 | TrainLoss: 3.368e-03 | Val MSE: 6.032e-06 | Max Val |err|: 1.177e-02 | Time: 37.88s\n",
      "Epochs:  10000 | TrainLoss: 1.047e-03 | Val MSE: 2.392e-06 | Max Val |err|: 5.628e-03 | Time: 33.55s\n",
      "Epochs:  15000 | TrainLoss: 7.306e-04 | Val MSE: 1.775e-06 | Max Val |err|: 5.224e-03 | Time: 33.56s\n",
      "Epochs:  20000 | TrainLoss: 4.653e-03 | Val MSE: 4.418e-05 | Max Val |err|: 1.011e-02 | Time: 32.98s\n",
      "Epochs:  25000 | TrainLoss: 3.048e-04 | Val MSE: 9.870e-07 | Max Val |err|: 4.264e-03 | Time: 32.90s\n",
      "Epochs:  30000 | TrainLoss: 1.754e-04 | Val MSE: 4.751e-07 | Max Val |err|: 2.936e-03 | Time: 32.99s\n",
      "Epochs:  35000 | TrainLoss: 1.721e-04 | Val MSE: 5.231e-07 | Max Val |err|: 2.104e-03 | Time: 32.19s\n",
      "Epochs:  40000 | TrainLoss: 1.129e-04 | Val MSE: 3.237e-07 | Max Val |err|: 2.661e-03 | Time: 33.17s\n",
      "Epochs:  45000 | TrainLoss: 9.646e-05 | Val MSE: 2.499e-07 | Max Val |err|: 2.442e-03 | Time: 33.44s\n",
      "Epochs:  50000 | TrainLoss: 8.475e-05 | Val MSE: 2.295e-07 | Max Val |err|: 2.386e-03 | Time: 32.83s\n",
      "Epochs:  55000 | TrainLoss: 1.198e-03 | Val MSE: 4.019e-06 | Max Val |err|: 4.657e-03 | Time: 32.88s\n",
      "Epochs:  60000 | TrainLoss: 6.999e-05 | Val MSE: 2.158e-07 | Max Val |err|: 2.322e-03 | Time: 33.02s\n",
      "Epochs:  65000 | TrainLoss: 4.426e-04 | Val MSE: 2.289e-06 | Max Val |err|: 3.625e-03 | Time: 33.58s\n",
      "Epochs:  70000 | TrainLoss: 5.639e-05 | Val MSE: 1.663e-07 | Max Val |err|: 1.949e-03 | Time: 33.77s\n",
      "Epochs:  75000 | TrainLoss: 5.398e-03 | Val MSE: 3.580e-05 | Max Val |err|: 1.115e-02 | Time: 32.92s\n",
      "Epochs:  80000 | TrainLoss: 5.114e-05 | Val MSE: 1.442e-07 | Max Val |err|: 1.902e-03 | Time: 32.48s\n",
      "Epochs:  85000 | TrainLoss: 2.340e-04 | Val MSE: 1.790e-06 | Max Val |err|: 3.535e-03 | Time: 31.97s\n",
      "Epochs:  90000 | TrainLoss: 4.400e-05 | Val MSE: 1.262e-07 | Max Val |err|: 1.569e-03 | Time: 31.92s\n",
      "Epochs:  95000 | TrainLoss: 6.119e-04 | Val MSE: 1.709e-06 | Max Val |err|: 3.052e-03 | Time: 32.37s\n",
      "Total training time: 663.73 s\n",
      "Best Val MSE: 1.152e-07 at epoch 99922\n",
      "Best Max |err| on validation: 1.656e-03\n",
      "\n",
      "=== Sweep N_b = 101 (N_i=101, N_k=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 1.186e+01 | Val MSE: 9.775e-02 | Max Val |err|: 8.150e-01 | Time: 0.04s\n",
      "Epochs:   5000 | TrainLoss: 3.288e-03 | Val MSE: 6.819e-06 | Max Val |err|: 1.266e-02 | Time: 39.46s\n",
      "Epochs:  10000 | TrainLoss: 1.682e-03 | Val MSE: 3.731e-06 | Max Val |err|: 9.971e-03 | Time: 36.23s\n",
      "Epochs:  15000 | TrainLoss: 1.331e-03 | Val MSE: 5.762e-06 | Max Val |err|: 9.326e-03 | Time: 36.06s\n",
      "Epochs:  20000 | TrainLoss: 1.328e-03 | Val MSE: 4.762e-06 | Max Val |err|: 9.826e-03 | Time: 35.30s\n",
      "Epochs:  25000 | TrainLoss: 1.515e-03 | Val MSE: 1.332e-05 | Max Val |err|: 6.526e-03 | Time: 35.62s\n",
      "Epochs:  30000 | TrainLoss: 2.340e-03 | Val MSE: 4.380e-06 | Max Val |err|: 8.510e-03 | Time: 36.86s\n",
      "Epochs:  35000 | TrainLoss: 3.363e-04 | Val MSE: 8.667e-07 | Max Val |err|: 4.097e-03 | Time: 36.10s\n",
      "Epochs:  40000 | TrainLoss: 3.247e-03 | Val MSE: 4.128e-05 | Max Val |err|: 9.661e-03 | Time: 36.29s\n",
      "Epochs:  45000 | TrainLoss: 2.892e-04 | Val MSE: 1.265e-06 | Max Val |err|: 4.845e-03 | Time: 36.23s\n",
      "Epochs:  50000 | TrainLoss: 3.133e-04 | Val MSE: 1.364e-06 | Max Val |err|: 4.577e-03 | Time: 36.25s\n",
      "Epochs:  55000 | TrainLoss: 2.006e-04 | Val MSE: 7.074e-07 | Max Val |err|: 3.828e-03 | Time: 35.80s\n",
      "Epochs:  60000 | TrainLoss: 2.460e-04 | Val MSE: 7.842e-07 | Max Val |err|: 2.538e-03 | Time: 29.77s\n",
      "Epochs:  65000 | TrainLoss: 2.158e-04 | Val MSE: 5.623e-07 | Max Val |err|: 2.436e-03 | Time: 17.76s\n",
      "Epochs:  70000 | TrainLoss: 1.334e-04 | Val MSE: 4.004e-07 | Max Val |err|: 2.887e-03 | Time: 17.63s\n",
      "Epochs:  75000 | TrainLoss: 3.011e-03 | Val MSE: 8.470e-06 | Max Val |err|: 4.385e-03 | Time: 17.46s\n",
      "Epochs:  80000 | TrainLoss: 4.798e-04 | Val MSE: 1.164e-06 | Max Val |err|: 2.512e-03 | Time: 18.07s\n",
      "Epochs:  85000 | TrainLoss: 1.028e-04 | Val MSE: 2.734e-07 | Max Val |err|: 2.514e-03 | Time: 17.75s\n",
      "Epochs:  90000 | TrainLoss: 7.701e-03 | Val MSE: 5.795e-05 | Max Val |err|: 1.185e-02 | Time: 17.87s\n",
      "Epochs:  95000 | TrainLoss: 9.009e-05 | Val MSE: 2.494e-07 | Max Val |err|: 2.466e-03 | Time: 17.48s\n",
      "Total training time: 571.86 s\n",
      "Best Val MSE: 2.524e-07 at epoch 99935\n",
      "Best Max |err| on validation: 2.452e-03\n",
      "\n",
      "N_b sweep summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_i</th>\n",
       "      <th>N_b</th>\n",
       "      <th>N_k</th>\n",
       "      <th>N_f</th>\n",
       "      <th>total_elapsed</th>\n",
       "      <th>best_ep</th>\n",
       "      <th>best_TL</th>\n",
       "      <th>best_v</th>\n",
       "      <th>best_max_err</th>\n",
       "      <th>rel_L2</th>\n",
       "      <th>loss_values</th>\n",
       "      <th>mse_v_hist</th>\n",
       "      <th>max_errors</th>\n",
       "      <th>training_curve_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>603.245504</td>\n",
       "      <td>99726</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>2.450000e-07</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>[35.49047088623047, 31.64017677307129, 28.8268...</td>\n",
       "      <td>[(0, 0.18902820348739624), (1, 0.1723163574934...</td>\n",
       "      <td>[(0, 0.7979638576507568), (1, 0.75469136238098...</td>\n",
       "      <td>sweep_Nb/train_Ni101_Nb11_Nk51_Nf1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>595.702620</td>\n",
       "      <td>99960</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>8.869490e-08</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>[44.46357345581055, 36.97004699707031, 30.7512...</td>\n",
       "      <td>[(0, 0.13326984643936157), (1, 0.1177368164062...</td>\n",
       "      <td>[(0, 1.0488758087158203), (1, 0.98042356967926...</td>\n",
       "      <td>sweep_Nb/train_Ni101_Nb21_Nk51_Nf1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>663.738427</td>\n",
       "      <td>99922</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.151673e-07</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>[44.688880920410156, 37.15054702758789, 30.641...</td>\n",
       "      <td>[(0, 0.169343501329422), (1, 0.145464271306991...</td>\n",
       "      <td>[(0, 1.0646004676818848), (1, 1.01183891296386...</td>\n",
       "      <td>sweep_Nb/train_Ni101_Nb51_Nk51_Nf1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>571.894666</td>\n",
       "      <td>99935</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>2.524136e-07</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>[11.859679222106934, 9.724340438842773, 8.4731...</td>\n",
       "      <td>[(0, 0.0977526530623436), (1, 0.08888407796621...</td>\n",
       "      <td>[(0, 0.8150274157524109), (1, 0.76064717769622...</td>\n",
       "      <td>sweep_Nb/train_Ni101_Nb101_Nk51_Nf1000.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   N_i  N_b  N_k   N_f  total_elapsed  best_ep   best_TL        best_v  \\\n",
       "0  101   11   51  1000     603.245504    99726  0.000085  2.450000e-07   \n",
       "1  101   21   51  1000     595.702620    99960  0.000035  8.869490e-08   \n",
       "2  101   51   51  1000     663.738427    99922  0.000036  1.151673e-07   \n",
       "3  101  101   51  1000     571.894666    99935  0.000085  2.524136e-07   \n",
       "\n",
       "   best_max_err    rel_L2                                        loss_values  \\\n",
       "0      0.002273  0.001077  [35.49047088623047, 31.64017677307129, 28.8268...   \n",
       "1      0.001138  0.000763  [44.46357345581055, 36.97004699707031, 30.7512...   \n",
       "2      0.001656  0.000483  [44.688880920410156, 37.15054702758789, 30.641...   \n",
       "3      0.002452  0.001005  [11.859679222106934, 9.724340438842773, 8.4731...   \n",
       "\n",
       "                                          mse_v_hist  \\\n",
       "0  [(0, 0.18902820348739624), (1, 0.1723163574934...   \n",
       "1  [(0, 0.13326984643936157), (1, 0.1177368164062...   \n",
       "2  [(0, 0.169343501329422), (1, 0.145464271306991...   \n",
       "3  [(0, 0.0977526530623436), (1, 0.08888407796621...   \n",
       "\n",
       "                                          max_errors  \\\n",
       "0  [(0, 0.7979638576507568), (1, 0.75469136238098...   \n",
       "1  [(0, 1.0488758087158203), (1, 0.98042356967926...   \n",
       "2  [(0, 1.0646004676818848), (1, 1.01183891296386...   \n",
       "3  [(0, 0.8150274157524109), (1, 0.76064717769622...   \n",
       "\n",
       "                          training_curve_path  \n",
       "0   sweep_Nb/train_Ni101_Nb11_Nk51_Nf1000.png  \n",
       "1   sweep_Nb/train_Ni101_Nb21_Nk51_Nf1000.png  \n",
       "2   sweep_Nb/train_Ni101_Nb51_Nk51_Nf1000.png  \n",
       "3  sweep_Nb/train_Ni101_Nb101_Nk51_Nf1000.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sweep N_k = 11 (N_i=101, N_b=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 3.067e+01 | Val MSE: 1.941e-01 | Max Val |err|: 6.626e-01 | Time: 0.00s\n",
      "Epochs:   5000 | TrainLoss: 2.305e-03 | Val MSE: 4.358e-06 | Max Val |err|: 1.028e-02 | Time: 16.72s\n",
      "Epochs:  10000 | TrainLoss: 9.259e-04 | Val MSE: 2.452e-06 | Max Val |err|: 4.786e-03 | Time: 15.49s\n",
      "Epochs:  15000 | TrainLoss: 4.043e-04 | Val MSE: 6.797e-07 | Max Val |err|: 4.319e-03 | Time: 15.82s\n",
      "Epochs:  20000 | TrainLoss: 3.693e-04 | Val MSE: 7.742e-07 | Max Val |err|: 3.417e-03 | Time: 15.58s\n",
      "Epochs:  25000 | TrainLoss: 2.378e-04 | Val MSE: 4.292e-07 | Max Val |err|: 3.098e-03 | Time: 15.48s\n",
      "Epochs:  30000 | TrainLoss: 5.748e-04 | Val MSE: 2.852e-06 | Max Val |err|: 4.676e-03 | Time: 14.73s\n",
      "Epochs:  35000 | TrainLoss: 1.974e-04 | Val MSE: 3.760e-07 | Max Val |err|: 3.058e-03 | Time: 14.69s\n",
      "Epochs:  40000 | TrainLoss: 1.551e-04 | Val MSE: 5.418e-07 | Max Val |err|: 2.782e-03 | Time: 14.82s\n",
      "Epochs:  45000 | TrainLoss: 3.233e-03 | Val MSE: 1.528e-05 | Max Val |err|: 7.544e-03 | Time: 14.57s\n",
      "Epochs:  50000 | TrainLoss: 1.097e-04 | Val MSE: 3.179e-07 | Max Val |err|: 2.755e-03 | Time: 14.73s\n",
      "Epochs:  55000 | TrainLoss: 1.274e-04 | Val MSE: 2.824e-07 | Max Val |err|: 2.334e-03 | Time: 15.10s\n",
      "Epochs:  60000 | TrainLoss: 9.199e-05 | Val MSE: 2.690e-07 | Max Val |err|: 2.406e-03 | Time: 14.76s\n",
      "Epochs:  65000 | TrainLoss: 4.044e-04 | Val MSE: 8.897e-06 | Max Val |err|: 6.478e-03 | Time: 15.25s\n",
      "Epochs:  70000 | TrainLoss: 3.282e-04 | Val MSE: 5.823e-06 | Max Val |err|: 4.482e-03 | Time: 15.86s\n",
      "Epochs:  75000 | TrainLoss: 3.040e-04 | Val MSE: 4.434e-06 | Max Val |err|: 3.674e-03 | Time: 14.67s\n",
      "Epochs:  80000 | TrainLoss: 1.561e-04 | Val MSE: 5.806e-07 | Max Val |err|: 2.390e-03 | Time: 14.71s\n",
      "Epochs:  85000 | TrainLoss: 4.632e-04 | Val MSE: 5.708e-06 | Max Val |err|: 4.289e-03 | Time: 14.68s\n",
      "Epochs:  90000 | TrainLoss: 7.392e-05 | Val MSE: 1.911e-07 | Max Val |err|: 2.064e-03 | Time: 14.54s\n",
      "Epochs:  95000 | TrainLoss: 9.591e-05 | Val MSE: 1.376e-06 | Max Val |err|: 3.818e-03 | Time: 14.66s\n",
      "Total training time: 301.51 s\n",
      "Best Val MSE: 1.557e-07 at epoch 99645\n",
      "Best Max |err| on validation: 2.076e-03\n",
      "\n",
      "=== Sweep N_k = 21 (N_i=101, N_b=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 3.196e+01 | Val MSE: 1.392e-01 | Max Val |err|: 1.076e+00 | Time: 0.00s\n",
      "Epochs:   5000 | TrainLoss: 3.228e-03 | Val MSE: 5.706e-06 | Max Val |err|: 1.274e-02 | Time: 15.90s\n",
      "Epochs:  10000 | TrainLoss: 9.328e-04 | Val MSE: 1.704e-06 | Max Val |err|: 7.602e-03 | Time: 14.99s\n",
      "Epochs:  15000 | TrainLoss: 1.668e-03 | Val MSE: 2.431e-05 | Max Val |err|: 9.834e-03 | Time: 14.82s\n",
      "Epochs:  20000 | TrainLoss: 8.109e-04 | Val MSE: 5.341e-06 | Max Val |err|: 6.473e-03 | Time: 14.71s\n",
      "Epochs:  25000 | TrainLoss: 3.004e-04 | Val MSE: 6.535e-07 | Max Val |err|: 4.118e-03 | Time: 14.72s\n",
      "Epochs:  30000 | TrainLoss: 2.563e-04 | Val MSE: 5.750e-07 | Max Val |err|: 3.439e-03 | Time: 14.75s\n",
      "Epochs:  35000 | TrainLoss: 4.617e-04 | Val MSE: 3.890e-06 | Max Val |err|: 4.714e-03 | Time: 14.80s\n",
      "Epochs:  40000 | TrainLoss: 3.803e-03 | Val MSE: 1.998e-05 | Max Val |err|: 8.900e-03 | Time: 14.78s\n",
      "Epochs:  45000 | TrainLoss: 2.016e-04 | Val MSE: 8.691e-07 | Max Val |err|: 3.586e-03 | Time: 15.01s\n",
      "Epochs:  50000 | TrainLoss: 6.920e-04 | Val MSE: 2.536e-06 | Max Val |err|: 4.198e-03 | Time: 14.82s\n",
      "Epochs:  55000 | TrainLoss: 3.122e-03 | Val MSE: 3.696e-05 | Max Val |err|: 8.199e-03 | Time: 14.70s\n",
      "Epochs:  60000 | TrainLoss: 5.154e-04 | Val MSE: 6.830e-06 | Max Val |err|: 5.101e-03 | Time: 15.66s\n",
      "Epochs:  65000 | TrainLoss: 2.120e-04 | Val MSE: 8.919e-07 | Max Val |err|: 2.919e-03 | Time: 15.77s\n",
      "Epochs:  70000 | TrainLoss: 1.889e-04 | Val MSE: 4.112e-07 | Max Val |err|: 2.076e-03 | Time: 14.91s\n",
      "Epochs:  75000 | TrainLoss: 1.632e-04 | Val MSE: 4.746e-06 | Max Val |err|: 4.762e-03 | Time: 14.89s\n",
      "Epochs:  80000 | TrainLoss: 1.069e-04 | Val MSE: 2.725e-07 | Max Val |err|: 2.347e-03 | Time: 15.83s\n",
      "Epochs:  85000 | TrainLoss: 1.810e-04 | Val MSE: 1.068e-06 | Max Val |err|: 2.917e-03 | Time: 15.74s\n",
      "Epochs:  90000 | TrainLoss: 1.788e-04 | Val MSE: 1.888e-06 | Max Val |err|: 3.168e-03 | Time: 15.12s\n",
      "Epochs:  95000 | TrainLoss: 1.213e-04 | Val MSE: 2.694e-07 | Max Val |err|: 2.220e-03 | Time: 14.77s\n",
      "Total training time: 301.43 s\n",
      "Best Val MSE: 2.135e-07 at epoch 99947\n",
      "Best Max |err| on validation: 2.097e-03\n",
      "\n",
      "=== Sweep N_k = 51 (N_i=101, N_b=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 2.678e+01 | Val MSE: 1.975e-01 | Max Val |err|: 1.061e+00 | Time: 0.00s\n",
      "Epochs:   5000 | TrainLoss: 5.122e-03 | Val MSE: 8.005e-06 | Max Val |err|: 1.394e-02 | Time: 16.57s\n",
      "Epochs:  10000 | TrainLoss: 1.631e-03 | Val MSE: 3.309e-06 | Max Val |err|: 9.509e-03 | Time: 16.00s\n",
      "Epochs:  15000 | TrainLoss: 8.630e-04 | Val MSE: 2.039e-06 | Max Val |err|: 7.245e-03 | Time: 16.34s\n",
      "Epochs:  20000 | TrainLoss: 5.321e-04 | Val MSE: 1.431e-06 | Max Val |err|: 6.319e-03 | Time: 16.34s\n",
      "Epochs:  25000 | TrainLoss: 7.083e-04 | Val MSE: 7.097e-06 | Max Val |err|: 5.259e-03 | Time: 15.69s\n",
      "Epochs:  30000 | TrainLoss: 2.919e-04 | Val MSE: 9.309e-07 | Max Val |err|: 4.969e-03 | Time: 15.46s\n",
      "Epochs:  35000 | TrainLoss: 5.569e-04 | Val MSE: 5.771e-06 | Max Val |err|: 5.589e-03 | Time: 15.36s\n",
      "Epochs:  40000 | TrainLoss: 2.513e-04 | Val MSE: 1.280e-06 | Max Val |err|: 5.387e-03 | Time: 15.66s\n",
      "Epochs:  45000 | TrainLoss: 1.530e-03 | Val MSE: 9.987e-06 | Max Val |err|: 8.264e-03 | Time: 16.35s\n",
      "Epochs:  50000 | TrainLoss: 2.916e-03 | Val MSE: 1.851e-05 | Max Val |err|: 8.588e-03 | Time: 15.51s\n",
      "Epochs:  55000 | TrainLoss: 1.457e-04 | Val MSE: 7.628e-07 | Max Val |err|: 4.433e-03 | Time: 15.43s\n",
      "Epochs:  60000 | TrainLoss: 1.038e-04 | Val MSE: 4.558e-07 | Max Val |err|: 4.055e-03 | Time: 15.59s\n",
      "Epochs:  65000 | TrainLoss: 1.185e-03 | Val MSE: 1.958e-06 | Max Val |err|: 3.281e-03 | Time: 15.55s\n",
      "Epochs:  70000 | TrainLoss: 2.373e-03 | Val MSE: 1.026e-05 | Max Val |err|: 7.385e-03 | Time: 15.72s\n",
      "Epochs:  75000 | TrainLoss: 1.893e-04 | Val MSE: 9.407e-07 | Max Val |err|: 3.814e-03 | Time: 15.67s\n",
      "Epochs:  80000 | TrainLoss: 1.745e-03 | Val MSE: 2.761e-05 | Max Val |err|: 7.724e-03 | Time: 15.38s\n",
      "Epochs:  85000 | TrainLoss: 6.710e-05 | Val MSE: 1.750e-07 | Max Val |err|: 2.900e-03 | Time: 15.42s\n",
      "Epochs:  90000 | TrainLoss: 6.288e-05 | Val MSE: 1.471e-07 | Max Val |err|: 2.600e-03 | Time: 15.41s\n",
      "Epochs:  95000 | TrainLoss: 1.201e-04 | Val MSE: 4.505e-07 | Max Val |err|: 2.999e-03 | Time: 15.43s\n",
      "Total training time: 314.28 s\n",
      "Best Val MSE: 1.319e-07 at epoch 99448\n",
      "Best Max |err| on validation: 2.512e-03\n",
      "\n",
      "=== Sweep N_k = 101 (N_i=101, N_b=51, N_f=1000) ===\n",
      "Epochs:      0 | TrainLoss: 2.063e+01 | Val MSE: 1.366e-01 | Max Val |err|: 7.761e-01 | Time: 0.02s\n",
      "Epochs:   5000 | TrainLoss: 2.825e-03 | Val MSE: 6.263e-06 | Max Val |err|: 1.012e-02 | Time: 19.42s\n",
      "Epochs:  10000 | TrainLoss: 1.034e-03 | Val MSE: 2.416e-06 | Max Val |err|: 6.394e-03 | Time: 18.71s\n",
      "Epochs:  15000 | TrainLoss: 5.319e-04 | Val MSE: 1.269e-06 | Max Val |err|: 4.668e-03 | Time: 18.66s\n",
      "Epochs:  20000 | TrainLoss: 3.149e-04 | Val MSE: 7.565e-07 | Max Val |err|: 3.879e-03 | Time: 18.54s\n",
      "Epochs:  25000 | TrainLoss: 4.876e-04 | Val MSE: 9.680e-07 | Max Val |err|: 2.730e-03 | Time: 18.49s\n",
      "Epochs:  30000 | TrainLoss: 1.717e-04 | Val MSE: 3.929e-07 | Max Val |err|: 2.623e-03 | Time: 18.53s\n",
      "Epochs:  35000 | TrainLoss: 1.225e-03 | Val MSE: 8.059e-06 | Max Val |err|: 4.834e-03 | Time: 18.53s\n",
      "Epochs:  40000 | TrainLoss: 1.768e-04 | Val MSE: 3.727e-07 | Max Val |err|: 2.196e-03 | Time: 18.55s\n",
      "Epochs:  45000 | TrainLoss: 1.012e-04 | Val MSE: 2.034e-07 | Max Val |err|: 1.947e-03 | Time: 18.48s\n",
      "Epochs:  50000 | TrainLoss: 1.013e-03 | Val MSE: 7.430e-06 | Max Val |err|: 5.299e-03 | Time: 18.50s\n",
      "Epochs:  55000 | TrainLoss: 8.253e-05 | Val MSE: 1.443e-07 | Max Val |err|: 1.597e-03 | Time: 18.49s\n",
      "Epochs:  60000 | TrainLoss: 8.998e-05 | Val MSE: 2.696e-06 | Max Val |err|: 3.600e-03 | Time: 18.55s\n",
      "Epochs:  65000 | TrainLoss: 8.795e-05 | Val MSE: 2.650e-07 | Max Val |err|: 1.688e-03 | Time: 18.48s\n",
      "Epochs:  70000 | TrainLoss: 1.007e-04 | Val MSE: 2.625e-07 | Max Val |err|: 1.576e-03 | Time: 18.49s\n",
      "Epochs:  75000 | TrainLoss: 7.836e-05 | Val MSE: 2.181e-07 | Max Val |err|: 1.438e-03 | Time: 18.48s\n",
      "Epochs:  80000 | TrainLoss: 4.723e-04 | Val MSE: 1.393e-06 | Max Val |err|: 2.167e-03 | Time: 18.42s\n",
      "Epochs:  85000 | TrainLoss: 7.288e-04 | Val MSE: 2.722e-07 | Max Val |err|: 1.353e-03 | Time: 18.50s\n",
      "Epochs:  90000 | TrainLoss: 7.905e-05 | Val MSE: 3.280e-07 | Max Val |err|: 1.397e-03 | Time: 18.40s\n",
      "Epochs:  95000 | TrainLoss: 1.339e-03 | Val MSE: 9.458e-06 | Max Val |err|: 5.217e-03 | Time: 18.41s\n",
      "Total training time: 371.07 s\n",
      "Best Val MSE: 7.216e-08 at epoch 99958\n",
      "Best Max |err| on validation: 1.092e-03\n",
      "\n",
      "N_k sweep summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_i</th>\n",
       "      <th>N_b</th>\n",
       "      <th>N_k</th>\n",
       "      <th>N_f</th>\n",
       "      <th>total_elapsed</th>\n",
       "      <th>best_ep</th>\n",
       "      <th>best_TL</th>\n",
       "      <th>best_v</th>\n",
       "      <th>best_max_err</th>\n",
       "      <th>rel_L2</th>\n",
       "      <th>loss_values</th>\n",
       "      <th>mse_v_hist</th>\n",
       "      <th>max_errors</th>\n",
       "      <th>training_curve_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>301.514683</td>\n",
       "      <td>99645</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1.557201e-07</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>[30.67354965209961, 25.916240692138672, 21.867...</td>\n",
       "      <td>[(0, 0.1940578818321228), (1, 0.16086277365684...</td>\n",
       "      <td>[(0, 0.6626036763191223), (1, 0.60622304677963...</td>\n",
       "      <td>sweep_Nk/train_Ni101_Nb51_Nk11_Nf1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>1000</td>\n",
       "      <td>301.428975</td>\n",
       "      <td>99947</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>2.134577e-07</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>[31.9571475982666, 25.611705780029297, 20.4957...</td>\n",
       "      <td>[(0, 0.13916951417922974), (1, 0.1182712540030...</td>\n",
       "      <td>[(0, 1.0757888555526733), (1, 0.99708050489425...</td>\n",
       "      <td>sweep_Nk/train_Ni101_Nb51_Nk21_Nf1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1000</td>\n",
       "      <td>314.278008</td>\n",
       "      <td>99448</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.319239e-07</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>[26.78264045715332, 22.83032989501953, 19.5598...</td>\n",
       "      <td>[(0, 0.1974918395280838), (1, 0.17030608654022...</td>\n",
       "      <td>[(0, 1.0612671375274658), (1, 0.99739074707031...</td>\n",
       "      <td>sweep_Nk/train_Ni101_Nb51_Nk51_Nf1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>101</td>\n",
       "      <td>1000</td>\n",
       "      <td>371.071773</td>\n",
       "      <td>99958</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>7.216311e-08</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>[20.62648582458496, 17.80280113220215, 15.5296...</td>\n",
       "      <td>[(0, 0.13663625717163086), (1, 0.1185233294963...</td>\n",
       "      <td>[(0, 0.7760787606239319), (1, 0.71771323680877...</td>\n",
       "      <td>sweep_Nk/train_Ni101_Nb51_Nk101_Nf1000.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   N_i  N_b  N_k   N_f  total_elapsed  best_ep   best_TL        best_v  \\\n",
       "0  101   51   11  1000     301.514683    99645  0.000046  1.557201e-07   \n",
       "1  101   51   21  1000     301.428975    99947  0.000082  2.134577e-07   \n",
       "2  101   51   51  1000     314.278008    99448  0.000051  1.319239e-07   \n",
       "3  101   51  101  1000     371.071773    99958  0.000049  7.216311e-08   \n",
       "\n",
       "   best_max_err    rel_L2                                        loss_values  \\\n",
       "0      0.002076  0.000640  [30.67354965209961, 25.916240692138672, 21.867...   \n",
       "1      0.002097  0.000837  [31.9571475982666, 25.611705780029297, 20.4957...   \n",
       "2      0.002512  0.000591  [26.78264045715332, 22.83032989501953, 19.5598...   \n",
       "3      0.001092  0.000653  [20.62648582458496, 17.80280113220215, 15.5296...   \n",
       "\n",
       "                                          mse_v_hist  \\\n",
       "0  [(0, 0.1940578818321228), (1, 0.16086277365684...   \n",
       "1  [(0, 0.13916951417922974), (1, 0.1182712540030...   \n",
       "2  [(0, 0.1974918395280838), (1, 0.17030608654022...   \n",
       "3  [(0, 0.13663625717163086), (1, 0.1185233294963...   \n",
       "\n",
       "                                          max_errors  \\\n",
       "0  [(0, 0.6626036763191223), (1, 0.60622304677963...   \n",
       "1  [(0, 1.0757888555526733), (1, 0.99708050489425...   \n",
       "2  [(0, 1.0612671375274658), (1, 0.99739074707031...   \n",
       "3  [(0, 0.7760787606239319), (1, 0.71771323680877...   \n",
       "\n",
       "                          training_curve_path  \n",
       "0   sweep_Nk/train_Ni101_Nb51_Nk11_Nf1000.png  \n",
       "1   sweep_Nk/train_Ni101_Nb51_Nk21_Nf1000.png  \n",
       "2   sweep_Nk/train_Ni101_Nb51_Nk51_Nf1000.png  \n",
       "3  sweep_Nk/train_Ni101_Nb51_Nk101_Nf1000.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For readability: disable warnings from libraries like matplotlib, etc.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "# Make sure torch is imported somewhere above this cell:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "import time\n",
    "from itertools import product, combinations\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as la\n",
    "from pyDOE import lhs\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import LogLocator, FuncFormatter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "# --- Device Setup ---\n",
    "print(\"CUDA available?\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Select the most performant device available (CUDA > MPS > CPU)\n",
    "device = (\n",
    "    torch.device('cuda') if torch.cuda.is_available()\n",
    "    else torch.device('mps') if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
    "    else torch.device('cpu')\n",
    ")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "def u_true_numpy(X, T, logK):\n",
    "    \"\"\"Vectorised true solution: U = exp(-(pi^2) * T) * sin(pi * X).\"\"\"\n",
    "    K = 10.0**logK    # convert log10(k)  k\n",
    "    return np.exp(- K * (np.pi**2) * T) * np.sin(np.pi * X)\n",
    "\n",
    "def net_u(x, t, logk, model):\n",
    "    \"\"\"\n",
    "    NN input is (x, t, log10(k)).\n",
    "    \"\"\"\n",
    "    X = torch.cat([x, t, logk], dim=1)  # If x and t are each shape (N, 1), then X becomes (N, 2).\n",
    "    u = model(X)\n",
    "    return u\n",
    "\n",
    "# net_f computes the PDE residual\n",
    "# If f  0 at collocation points, the NN satisfies the equation there\n",
    "def net_f(x, t, logk, model):\n",
    "    x.requires_grad_(True)\n",
    "    t.requires_grad_(True)\n",
    "    # logk.requires_grad_(True)\n",
    "    \n",
    "    u = net_u(x, t, logk, model)\n",
    "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "    \n",
    "    # convert log10(k) -> k = 10^logk\n",
    "    k = 10.0**logk\n",
    "    \n",
    "    f = u_t - k * u_xx\n",
    "    return f\n",
    "\n",
    "class XavierInit(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(XavierInit, self).__init__()\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = torch.sqrt(torch.tensor(2.0 / (in_dim + out_dim)))\n",
    "        self.weight = nn.Parameter(torch.randn(in_dim, out_dim) * xavier_stddev)\n",
    "        self.bias = nn.Parameter(torch.zeros(out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.weight) + self.bias\n",
    "\n",
    "def initialize_NN(layers):\n",
    "    weights = nn.ModuleList()\n",
    "    num_layers = len(layers)\n",
    "    for l in range(num_layers - 1):\n",
    "        layer = XavierInit(size=[layers[l], layers[l + 1]]) # if there was no retutn, how do I get the weight and bias?\n",
    "        weights.append(layer)\n",
    "    return weights\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, layers, lb, ub):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.weights = initialize_NN(layers)\n",
    "        # make lb/ub move with .to(device)\n",
    "        self.register_buffer('lb', torch.as_tensor(lb, dtype=torch.float32))     # <<< CHANGED >>>\n",
    "        self.register_buffer('ub', torch.as_tensor(ub, dtype=torch.float32))     # <<< CHANGED >>>\n",
    "        # self.register_buffer('k', torch.tensor(k_init, dtype=torch.float32))     # <<< CHANGED >>>\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.float()                                                            # <<< CHANGED >>>\n",
    "        lb = self.lb.to(X.device)                                                # <<< CHANGED >>>\n",
    "        ub = self.ub.to(X.device)                                                # <<< CHANGED >>>\n",
    "        H = 2.0 * (X - self.lb) / (self.ub - self.lb) - 1.0\n",
    "        for l in range(len(self.weights) - 1):\n",
    "            H = torch.tanh(self.weights[l](H.float()))     # Is this already a calculation?\n",
    "        Y = self.weights[-1](H)\n",
    "        return Y\n",
    "\n",
    "def train(nEpoch, X, u, X_f, X_val, model, learning_rate):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # ----- STAGE 1: start with Adam -----\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # when to switch from Adam to L-BFGS\n",
    "    switch_epoch = 100000\n",
    "    used_lbfgs   = False   \n",
    "    lbfgs_epochs   = 0.0           # <-- how many epochs of L-BFGS you want\n",
    "    lbfgs_start_ep = None          # <-- will store the epoch where we switch\n",
    "\n",
    "    # use the model's device\n",
    "    dev = next(model.parameters()).device                                        # <<< CHANGED >>>\n",
    "\n",
    "    x    = X[:, 0:1]\n",
    "    t    = X[:, 1:2]\n",
    "    logk = X[:, 2:3]\n",
    "    # Collocation points (f points)\n",
    "    x_f    = X_f[:, 0:1]\n",
    "    t_f    = X_f[:, 1:2]\n",
    "    logk_f = X_f[:, 2:3]\n",
    "    # Validation points\n",
    "    x_v    = X_val[:, 0:1]\n",
    "    t_v    = X_val[:, 1:2]\n",
    "    logk_v = X_val[:, 2:3]\n",
    "\n",
    "    # True validation solution (analytic)\n",
    "    u_v_true = u_true_numpy(x_v, t_v, logk_v)   # shape (N_val,)\n",
    "\n",
    "    # create tensors ON THE SAME DEVICE\n",
    "    x_tf      = torch.tensor(x,        dtype=torch.float32, device=dev, requires_grad=True)   # <<< CHANGED >>>\n",
    "    t_tf      = torch.tensor(t,        dtype=torch.float32, device=dev, requires_grad=True)   # <<< CHANGED >>>\n",
    "    logk_tf   = torch.tensor(logk,     dtype=torch.float32, device=dev, requires_grad=True)   # <<< CHANGED >>>\n",
    "    u_tf      = torch.tensor(u,        dtype=torch.float32, device=dev)                       # <<< CHANGED >>>\n",
    "    x_f_tf    = torch.tensor(x_f,      dtype=torch.float32, device=dev, requires_grad=True)   # <<< CHANGED >>>\n",
    "    t_f_tf    = torch.tensor(t_f,      dtype=torch.float32, device=dev, requires_grad=True)   # <<< CHANGED >>>\n",
    "    logk_f_tf = torch.tensor(logk_f,   dtype=torch.float32, device=dev, requires_grad=True)   # <<< CHANGED >>>\n",
    "    x_v_tf    = torch.tensor(x_v,      dtype=torch.float32, device=dev)\n",
    "    t_v_tf    = torch.tensor(t_v,      dtype=torch.float32, device=dev)\n",
    "    logk_v_tf = torch.tensor(logk_v,   dtype=torch.float32, device=dev)\n",
    "    u_true_tf = torch.tensor(u_v_true, dtype=torch.float32, device=dev).reshape(-1, 1)\n",
    "\n",
    "    mse_v_hist  = []\n",
    "    loss_values = []\n",
    "    max_errors  = []   # <<< NEW: to store (epoch, max_abs_error) >>>\n",
    "\n",
    "    patience  = 10000          # number of validations without improvement\n",
    "    pat       = 0\n",
    "    best_v    = float('inf')   # best validation MSE\n",
    "    best_TL   = float('inf')   # best training loss corresponding to best_v\n",
    "    best_max_err = float('inf')  # <<< NEW: best max |error| on val\n",
    "    best_state = copy.deepcopy(model.state_dict())\n",
    "    best_ep    = -1\n",
    "\n",
    "    start_time  = time.time()\n",
    "    total_start = time.time()        # total wall-clock timer\n",
    "\n",
    "    for ep in range(nEpoch):\n",
    "\n",
    "        # ----- Stop if we've done lbfgs_epochs of L-BFGS -----\n",
    "        if used_lbfgs and lbfgs_start_ep is not None:\n",
    "            if ep - lbfgs_start_ep >= lbfgs_epochs:\n",
    "                print(f\"Stopping after {lbfgs_epochs} LBFGS epochs at global epoch {ep}\")\n",
    "                break\n",
    "\n",
    "        # ------------------------------\n",
    "        # STAGE 1: Adam (ep < switch_epoch)\n",
    "        # STAGE 2: L-BFGS (ep >= switch_epoch)\n",
    "        # ------------------------------\n",
    "        if ep < switch_epoch:\n",
    "            # ----- Adam update -----\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Compute predictions for training data (u)\n",
    "            u_pred = net_u(x_tf, t_tf, logk_tf, model)          # <<< CHANGED\n",
    "            # Compute PDE residual at collocation points\n",
    "            u_f_pred = net_f(x_f_tf, t_f_tf, logk_f_tf, model)  # <<< CHANGED\n",
    "    \n",
    "            loss_PDE  = criterion(u_f_pred, torch.zeros_like(u_f_pred))\n",
    "            loss_data = criterion(u_tf, u_pred)\n",
    "            loss = loss_PDE + 100 * loss_data\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        else:\n",
    "            # ----- Switch to L-BFGS once -----\n",
    "            if not used_lbfgs:\n",
    "                # 1) Load the best Adam weights BEFORE creating LBFGS\n",
    "                model.load_state_dict(best_state)\n",
    "        \n",
    "                # 2) Print which Adam state you're starting from\n",
    "                print(\n",
    "                    f\"Switching to L-BFGS at epoch {ep} \"\n",
    "                    f\"-> starting from Adam best at epoch {best_ep} \"\n",
    "                    f\"(TrainLoss={best_TL:.3e}, Val MSE={best_v:.3e})\"\n",
    "                )\n",
    "        \n",
    "                # 3) Create the LBFGS optimiser on top of that state\n",
    "                optimizer = torch.optim.LBFGS(\n",
    "                    model.parameters(),\n",
    "                    max_iter=20,          # internal LBFGS iterations per .step()\n",
    "                    history_size=100,\n",
    "                    line_search_fn=None\n",
    "                )\n",
    "                used_lbfgs = True\n",
    "                lbfgs_start_ep = ep      # <-- remember when we switched\n",
    "                \n",
    "\n",
    "            # L-BFGS requires a closure that re-computes the loss\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                u_pred   = net_u(x_tf, t_tf, logk_tf, model)          # <<< CHANGED\n",
    "                u_f_pred = net_f(x_f_tf, t_f_tf, logk_f_tf, model)    # <<< CHANGED\n",
    "\n",
    "                loss_PDE  = criterion(u_f_pred, torch.zeros_like(u_f_pred))\n",
    "                loss_data = criterion(u_tf, u_pred)\n",
    "                loss      = loss_PDE + 100 * loss_data\n",
    "\n",
    "                loss.backward()\n",
    "                return loss\n",
    "\n",
    "            loss = optimizer.step(closure)  # returns the loss from the last closure call\n",
    "\n",
    "        \n",
    "        # ----- validation -----\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            u_v_pred = net_u(x_v_tf, t_v_tf, logk_v_tf, model)   # <<< CHANGED\n",
    "            mse_v = criterion(u_v_pred, u_true_tf).item()\n",
    "            mse_v_hist.append((ep, mse_v))\n",
    "\n",
    "            # <<< NEW: max absolute error on validation set >>>\n",
    "            abs_err = torch.abs(u_v_pred - u_true_tf)   # (N_val, 1)\n",
    "            max_err = abs_err.max().item()              # scalar\n",
    "            max_errors.append((ep, max_err))            # store (epoch, max_err)\n",
    "            # -----------------------------------------------\n",
    "\n",
    "        model.train()  # switch back\n",
    "\n",
    "\n",
    "        # ----- early stopping on val -----\n",
    "        # if mse_v < best_v:\n",
    "        if loss.item() < best_TL:\n",
    "            best_v       = mse_v\n",
    "            best_TL      = loss.item()\n",
    "            best_max_err = max_err          # <<< NEW: store max error at best state\n",
    "            best_state   = copy.deepcopy(model.state_dict())\n",
    "            best_ep      = ep\n",
    "            # print(f\"[Improved] Epoch {ep} | Best Val MSE: {best_v:.3e}\")\n",
    "            pat = 0\n",
    "        else:\n",
    "            pat += 1\n",
    "            if pat >= patience:\n",
    "                print(f\"Early stopping at it={ep}, best Val MSE={best_v:.3e}\")\n",
    "                break\n",
    "        \n",
    "        # Print progress\n",
    "        # - Before LBFGS: every 1000 epochs\n",
    "        # - After LBFGS is enabled: every 100 epochs\n",
    "        if (not used_lbfgs and ep % 5000 == 0) or (used_lbfgs and ep % 10 == 0):\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Epochs: {ep:6d} | TrainLoss: {loss.item():.3e} \"\n",
    "                  f\"| Val MSE: {mse_v:.3e} \"\n",
    "                  f\"| Max Val |err|: {max_err:.3e} \"   # <<< NEW\n",
    "                  f\"| Time: {elapsed:.2f}s\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "    total_elapsed = time.time() - total_start\n",
    "    print(f\"Total training time: {total_elapsed:.2f} s\")\n",
    "    print(f\"Best Val MSE: {best_v:.3e} at epoch {best_ep}\")\n",
    "    print(f\"Best Max |err| on validation: {best_max_err:.3e}\")   # <<< NEW\n",
    "\n",
    "    model.load_state_dict(best_state)          # <- load best here\n",
    "\n",
    "    return loss_values, mse_v_hist, max_errors, best_ep, best_TL, best_v, best_max_err\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Build dataset for arbitrary (N_i, N_b, N_k, N_f)\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_dataset(N_i, N_b, N_k, N_f, N_val,\n",
    "                  x_min, x_max,\n",
    "                  t_min, t_max,\n",
    "                  k_min, k_max,\n",
    "                  seed):\n",
    "    \"\"\"\n",
    "    Build training and collocation sets for the parametric heat equation.\n",
    "\n",
    "    Returns:\n",
    "        X_u_train : (N_u, 3) array of data points (x, t, log10(k)) for IC + BC.\n",
    "        u_train   : (N_u, 1) IC + BC at X_u_train.\n",
    "        X_f_train : (N_f, 3) collocation points in (x, t, log10(k)).\n",
    "        X_val     : (N_val, 3) validation points in (x, t, log10(k)).\n",
    "        lb, ub    : lower/upper bounds for normalisation in the NN.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- k and logk ---\n",
    "    # We sample k in [k_min, k_max] but represent it via log10(k).\n",
    "    logk_min = np.log10(k_min)\n",
    "    logk_max = np.log10(k_max)\n",
    "    logk_vec = np.linspace(logk_min, logk_max, N_k)  # equally spaced in log10(k)\n",
    "    k_vec    = 10.0**logk_vec                        # corresponding physical k\n",
    "\n",
    "    # --- Initial condition: u(x,0;k) = sin(pi x) ---\n",
    "    # x in [x_min, x_max], t=0, and all logk samples\n",
    "    x_ic = np.linspace(x_min, x_max, N_i)\n",
    "    t_ic = np.array([t_min])   # or [t_min]\n",
    "    x_ic_g, t_ic_g, logk_ic_g = np.meshgrid(x_ic, t_ic, logk_vec, indexing='ij')\n",
    "\n",
    "    x_u_ic    = x_ic_g.ravel()[:, None]\n",
    "    t_u_ic    = t_ic_g.ravel()[:, None]\n",
    "    logk_u_ic = logk_ic_g.ravel()[:, None]\n",
    "    X_u_train_ic = np.hstack([x_u_ic, t_u_ic, logk_u_ic])\n",
    "\n",
    "    # --- Boundary conditions: u(0,t;k)=0, u(1,t;k)=0 ---\n",
    "    # We discretise t with 2*N_b points between t_min and t_max.\n",
    "    t_line = np.linspace(t_min, t_max, 2 * N_b)\n",
    "    x_bc_left  = np.array([x_min])\n",
    "    x_bc_right = np.array([x_max])\n",
    "    x_bc = np.concatenate([x_bc_left, x_bc_right], axis=0)  # [0, 1]\n",
    "\n",
    "    x_bc_g, t_bc_g, logk_bc_g = np.meshgrid(x_bc, t_line, logk_vec, indexing='ij')\n",
    "    x_u_bc    = x_bc_g.ravel()[:, None]\n",
    "    t_u_bc    = t_bc_g.ravel()[:, None]\n",
    "    logk_u_bc = logk_bc_g.ravel()[:, None]\n",
    "    X_u_train_bc = np.hstack([x_u_bc, t_u_bc, logk_u_bc])\n",
    "\n",
    "    # --- Combine IC and BC into one \"data\" set ---\n",
    "    X_u_train = np.vstack([X_u_train_ic, X_u_train_bc]).astype(np.float32)\n",
    "\n",
    "    # --- Analytic solution for those IC/BC points ---\n",
    "    x_cal    = X_u_train[:, 0]\n",
    "    t_cal    = X_u_train[:, 1]\n",
    "    logk_cal = X_u_train[:, 2]\n",
    "    k_cal    = 10.0**logk_cal\n",
    "\n",
    "    # Closed-form solution: u(x,t;k) = exp(-k  t) sin( x)\n",
    "    u_train = np.exp(-k_cal * (np.pi**2) * t_cal) * np.sin(np.pi * x_cal)\n",
    "    u_train = u_train[:, None].astype(np.float32)\n",
    "\n",
    "    # --- Collocation + validation via LHS in (x, t, logk) ---\n",
    "    lb = np.array([x_min, t_min, logk_min], dtype=np.float32)\n",
    "    ub = np.array([x_max, t_max, logk_max], dtype=np.float32)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    U_all = lhs(3, samples=N_f + N_val)   # Latin Hypercube in [0,1]^3\n",
    "    X_all = lb + (ub - lb) * U_all        # map to [lb, ub] in (x, t, logk)\n",
    "    X_f_train = X_all[:N_f]\n",
    "    X_val     = X_all[N_f:]\n",
    "\n",
    "    return X_u_train, u_train, X_f_train, X_val, lb, ub\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Compute global relative L2 error for a trained model at a fixed k\n",
    "# -----------------------------------------------------------------------------\n",
    "def compute_rel_L2(model,\n",
    "                   x_min, x_max,\n",
    "                   t_min, t_max,\n",
    "                   k_val=1.0,\n",
    "                   Nx=100, Nt=100,\n",
    "                   device=device):\n",
    "    \"\"\"\n",
    "    Compute global relative L2 error of the model solution against the analytic\n",
    "    solution on a regular (x,t) grid at a fixed physical k = k_val.\n",
    "\n",
    "    rel_L2 = ||u_pred - u_true||_2 / ||u_true||_2\n",
    "    \"\"\"\n",
    "\n",
    "    # Build regular grid in x, t\n",
    "    x_test = np.linspace(x_min, x_max, Nx)\n",
    "    t_test = np.linspace(t_min, t_max, Nt)\n",
    "    logk_val = np.log10(k_val)  # convert to log10(k) for NN input\n",
    "\n",
    "    T, X = np.meshgrid(t_test, x_test, indexing='ij')  # shape (Nt, Nx)\n",
    "    LOGK = np.full_like(T, logk_val)                   # broadcast log10(k_val)\n",
    "\n",
    "    # Flatten to (Nt*Nx, 1) column vectors\n",
    "    x_flat    = X.ravel()[:, None]\n",
    "    t_flat    = T.ravel()[:, None]\n",
    "    logk_flat = LOGK.ravel()[:, None]\n",
    "\n",
    "    # Stack into (Nt*Nx, 3) array and convert to torch tensor\n",
    "    X_star    = np.hstack([x_flat, t_flat, logk_flat]).astype(np.float32)\n",
    "    X_star_tf = torch.from_numpy(X_star).to(device)\n",
    "\n",
    "    # NN prediction over the grid\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        u_pred = model(X_star_tf).squeeze(1).cpu().numpy().reshape(T.shape)\n",
    "\n",
    "    # Analytic solution on the same grid\n",
    "    u_true = u_true_numpy(X, T, LOGK)\n",
    "\n",
    "    # Global relative L2 error\n",
    "    num = np.linalg.norm(u_pred - u_true)\n",
    "    den = np.linalg.norm(u_true)\n",
    "    rel_L2 = num / den if den > 0 else num\n",
    "\n",
    "    return rel_L2\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Plot training curves (loss, val MSE, max |error|) and save to file\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_training_curves(loss_values, mse_v_hist, max_errors,\n",
    "                         N_i, N_b, N_k, N_f,\n",
    "                         out_dir=\"sweep_results\"):\n",
    "    \"\"\"\n",
    "    Make the TrainLoss / ValMSE / Max|Error| vs epoch plot and save to file.\n",
    "\n",
    "    Args:\n",
    "        loss_values : list of train loss per epoch\n",
    "        mse_v_hist  : list of (epoch, val_MSE)\n",
    "        max_errors  : list of (epoch, max_abs_error) on validation\n",
    "        N_i, N_b, N_k, N_f : configuration used (for filename)\n",
    "        out_dir     : directory where the PNG is saved\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Training loss epochs\n",
    "    ep_train = range(len(loss_values))\n",
    "\n",
    "    # Validation MSE: unpack (epoch, mse)\n",
    "    ep_val  = [int(i) for i, _ in mse_v_hist]\n",
    "    mse_val = [\n",
    "        (m.detach().cpu().item() if torch.is_tensor(m) else float(m))\n",
    "        for _, m in mse_v_hist\n",
    "    ]\n",
    "\n",
    "    # Max absolute error: unpack (epoch, max_err)\n",
    "    ep_max   = [int(i) for i, _ in max_errors]\n",
    "    max_errs = [\n",
    "        (m.detach().cpu().item() if torch.is_tensor(m) else float(m))\n",
    "        for _, m in max_errors\n",
    "    ]\n",
    "\n",
    "    # Plot curves on log scale (since errors/loss typically span many orders)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(ep_train, loss_values, color='black', label='Train Loss')\n",
    "    plt.plot(ep_val,   mse_val,     color='red',   label='Validation MSE')\n",
    "    plt.plot(ep_max,   max_errs,    color='blue',  label='Max |Error| (Validation)')\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss / Error')\n",
    "    plt.yscale('log')\n",
    "    plt.title('Training Loss, Validation MSE, and Max Validation Error vs Iterations')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # File name tagged with the configuration\n",
    "    fname = f\"train_Ni{N_i}_Nb{N_b}_Nk{N_k}_Nf{N_f}.png\"\n",
    "    fpath = os.path.join(out_dir, fname)\n",
    "    plt.savefig(fpath, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    return fpath\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Run a single experiment for given (N_i, N_b, N_k, N_f)\n",
    "# -----------------------------------------------------------------------------\n",
    "def run_single_experiment(N_i, N_b, N_k, N_f, seed,\n",
    "                          N_val=100,\n",
    "                          Train_epochs=100000,\n",
    "                          learning_rate=5e-4,\n",
    "                          k_val_eval=1.0,\n",
    "                          results_dir=\"sweep_results\"):\n",
    "    \"\"\"\n",
    "    Runs one full experiment:\n",
    "      - builds dataset for given (N_i, N_b, N_k, N_f)\n",
    "      - trains a fresh model\n",
    "      - saves training curve plot\n",
    "      - computes global rel L2 error at k = k_val_eval\n",
    "      - returns a dict with all requested info\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Build dataset (IC+BC data, collocation, validation, bounds)\n",
    "    X_u_train, u_train, X_f_train, X_val, lb, ub = build_dataset(\n",
    "        N_i=N_i, N_b=N_b, N_k=N_k, N_f=N_f, N_val=N_val,\n",
    "        x_min=x_min, x_max=x_max, t_min=t_min, t_max=t_max,\n",
    "        k_min=k_min, k_max=k_max, seed=seed\n",
    "    )\n",
    "\n",
    "    # 2) Initialise a new PINN model for this dataset\n",
    "    model = NeuralNet(layers, lb, ub).to(device).float()\n",
    "\n",
    "    # 3) Train and measure total wall-clock time for this configuration\n",
    "    exp_start = time.time()\n",
    "    loss_values, mse_v_hist, max_errors, best_ep, best_TL, best_v, best_max_err = train(\n",
    "        Train_epochs,\n",
    "        X_u_train,\n",
    "        u_train,\n",
    "        X_f_train,\n",
    "        X_val,\n",
    "        model,\n",
    "        learning_rate\n",
    "    )\n",
    "    total_elapsed = time.time() - exp_start\n",
    "\n",
    "    # 4) Compute global relative L2 error at a chosen k (e.g. k = 1.0)\n",
    "    rel_L2 = compute_rel_L2(\n",
    "        model,\n",
    "        x_min=x_min, x_max=x_max,\n",
    "        t_min=t_min, t_max=t_max,\n",
    "        k_val=k_val_eval,\n",
    "        Nx=100, Nt=100,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # 5) Create and save the training curve plot for this run\n",
    "    curve_path = plot_training_curves(\n",
    "        loss_values, mse_v_hist, max_errors,\n",
    "        N_i=N_i, N_b=N_b, N_k=N_k, N_f=N_f,\n",
    "        out_dir=results_dir\n",
    "    )\n",
    "\n",
    "    # 6) Pack all information into a record dictionary\n",
    "    record = {\n",
    "        \"N_i\": N_i,\n",
    "        \"N_b\": N_b,\n",
    "        \"N_k\": N_k,\n",
    "        \"N_f\": N_f,\n",
    "        \"total_elapsed\": total_elapsed,\n",
    "        \"best_ep\": best_ep,\n",
    "        \"best_TL\": best_TL,\n",
    "        \"best_v\": best_v,\n",
    "        \"best_max_err\": best_max_err,\n",
    "        \"rel_L2\": rel_L2,\n",
    "        \"loss_values\": loss_values,\n",
    "        \"mse_v_hist\": mse_v_hist,\n",
    "        \"max_errors\": max_errors,\n",
    "        \"training_curve_path\": curve_path,\n",
    "    }\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Sweep settings and loops for N_f, N_i, N_b, N_k\n",
    "# -----------------------------------------------------------------------------\n",
    "layers = [3, 50, 50, 50, 1]\n",
    "x_min=0.0\n",
    "x_max=1.0\n",
    "t_min=0.0\n",
    "t_max=0.25\n",
    "k_min=0.2\n",
    "k_max=2.0\n",
    "seed=123\n",
    "    \n",
    "# Base values (same as your current defaults)\n",
    "BASE_N_i = 101\n",
    "BASE_N_b = 51\n",
    "BASE_N_k = 51\n",
    "BASE_N_f = 1000\n",
    "\n",
    "# Training hyperparameters for all sweeps\n",
    "Train_epochs = 100000\n",
    "learning_rate = 0.0005\n",
    "N_val = 100          # number of validation points from LHS\n",
    "k_val_eval = 1.0     # k at which global rel L2 is computed\n",
    "\n",
    "# ==========================\n",
    "# Sweep 1: Collocation points N_f\n",
    "# ==========================\n",
    "Nf_list = [500, 1000, 2000, 4000]  # values to test for N_f\n",
    "\n",
    "results_Nf = []\n",
    "\n",
    "for N_f in Nf_list:\n",
    "    print(f\"\\n=== Sweep N_f = {N_f} (N_i={BASE_N_i}, N_b={BASE_N_b}, N_k={BASE_N_k}) ===\")\n",
    "    rec = run_single_experiment(\n",
    "        N_i=BASE_N_i,\n",
    "        N_b=BASE_N_b,\n",
    "        N_k=BASE_N_k,\n",
    "        N_f=N_f,\n",
    "        seed=123,\n",
    "        N_val=N_val,\n",
    "        Train_epochs=Train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        k_val_eval=k_val_eval,\n",
    "        results_dir=\"sweep_Nf\",\n",
    "    )\n",
    "    results_Nf.append(rec)\n",
    "\n",
    "# Convert list of records to DataFrame for easy inspection and saving\n",
    "df_Nf = pd.DataFrame([\n",
    "    {\n",
    "        \"N_i\": r[\"N_i\"], \"N_b\": r[\"N_b\"], \"N_k\": r[\"N_k\"], \"N_f\": r[\"N_f\"],\n",
    "        \"total_elapsed\": r[\"total_elapsed\"],\n",
    "        \"best_ep\": r[\"best_ep\"],\n",
    "        \"best_TL\": r[\"best_TL\"],\n",
    "        \"best_v\": r[\"best_v\"],\n",
    "        \"best_max_err\": r[\"best_max_err\"],\n",
    "        \"rel_L2\": r[\"rel_L2\"],\n",
    "        # Histories stored as objects (lists)  still useful inside Python\n",
    "        \"loss_values\": r[\"loss_values\"],\n",
    "        \"mse_v_hist\": r[\"mse_v_hist\"],\n",
    "        \"max_errors\": r[\"max_errors\"],\n",
    "        \"training_curve_path\": r[\"training_curve_path\"],\n",
    "    }\n",
    "    for r in results_Nf\n",
    "])\n",
    "\n",
    "print(\"\\nN_f sweep summary:\")\n",
    "display(df_Nf)\n",
    "\n",
    "# Save N_f sweep summary table as CSV\n",
    "df_Nf.to_csv(\"sweep_Nf_summary.csv\", index=False)\n",
    "\n",
    "# ==========================\n",
    "# Sweep 2: IC points N_i\n",
    "# ==========================\n",
    "Ni_list = [21, 51, 101, 201]  # values to test for N_i\n",
    "\n",
    "results_Ni = []\n",
    "\n",
    "for N_i in Ni_list:\n",
    "    print(f\"\\n=== Sweep N_i = {N_i} (N_b={BASE_N_b}, N_k={BASE_N_k}, N_f={BASE_N_f}) ===\")\n",
    "    rec = run_single_experiment(\n",
    "        N_i=N_i,\n",
    "        N_b=BASE_N_b,\n",
    "        N_k=BASE_N_k,\n",
    "        N_f=BASE_N_f,\n",
    "        N_val=N_val,\n",
    "        Train_epochs=Train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        k_val_eval=k_val_eval,\n",
    "        results_dir=\"sweep_Ni\",\n",
    "        seed=123\n",
    "    )\n",
    "    results_Ni.append(rec)\n",
    "\n",
    "df_Ni = pd.DataFrame([\n",
    "    {\n",
    "        \"N_i\": r[\"N_i\"], \"N_b\": r[\"N_b\"], \"N_k\": r[\"N_k\"], \"N_f\": r[\"N_f\"],\n",
    "        \"total_elapsed\": r[\"total_elapsed\"],\n",
    "        \"best_ep\": r[\"best_ep\"],\n",
    "        \"best_TL\": r[\"best_TL\"],\n",
    "        \"best_v\": r[\"best_v\"],\n",
    "        \"best_max_err\": r[\"best_max_err\"],\n",
    "        \"rel_L2\": r[\"rel_L2\"],\n",
    "        \"loss_values\": r[\"loss_values\"],\n",
    "        \"mse_v_hist\": r[\"mse_v_hist\"],\n",
    "        \"max_errors\": r[\"max_errors\"],\n",
    "        \"training_curve_path\": r[\"training_curve_path\"],\n",
    "    }\n",
    "    for r in results_Ni\n",
    "])\n",
    "\n",
    "print(\"\\nN_i sweep summary:\")\n",
    "display(df_Ni)\n",
    "\n",
    "df_Ni.to_csv(\"sweep_Ni_summary.csv\", index=False)\n",
    "\n",
    "# ==========================\n",
    "# Sweep 3: BC points N_b\n",
    "# ==========================\n",
    "Nb_list = [11, 21, 51, 101]  # values to test for N_b\n",
    "\n",
    "results_Nb = []\n",
    "\n",
    "for N_b in Nb_list:\n",
    "    print(f\"\\n=== Sweep N_b = {N_b} (N_i={BASE_N_i}, N_k={BASE_N_k}, N_f={BASE_N_f}) ===\")\n",
    "    rec = run_single_experiment(\n",
    "        N_i=BASE_N_i,\n",
    "        N_b=N_b,\n",
    "        N_k=BASE_N_k,\n",
    "        N_f=BASE_N_f,\n",
    "        N_val=N_val,\n",
    "        Train_epochs=Train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        k_val_eval=k_val_eval,\n",
    "        results_dir=\"sweep_Nb\",\n",
    "        seed=123\n",
    "    )\n",
    "    results_Nb.append(rec)\n",
    "\n",
    "df_Nb = pd.DataFrame([\n",
    "    {\n",
    "        \"N_i\": r[\"N_i\"], \"N_b\": r[\"N_b\"], \"N_k\": r[\"N_k\"], \"N_f\": r[\"N_f\"],\n",
    "        \"total_elapsed\": r[\"total_elapsed\"],\n",
    "        \"best_ep\": r[\"best_ep\"],\n",
    "        \"best_TL\": r[\"best_TL\"],\n",
    "        \"best_v\": r[\"best_v\"],\n",
    "        \"best_max_err\": r[\"best_max_err\"],\n",
    "        \"rel_L2\": r[\"rel_L2\"],\n",
    "        \"loss_values\": r[\"loss_values\"],\n",
    "        \"mse_v_hist\": r[\"mse_v_hist\"],\n",
    "        \"max_errors\": r[\"max_errors\"],\n",
    "        \"training_curve_path\": r[\"training_curve_path\"],\n",
    "    }\n",
    "    for r in results_Nb\n",
    "])\n",
    "\n",
    "print(\"\\nN_b sweep summary:\")\n",
    "display(df_Nb)\n",
    "\n",
    "df_Nb.to_csv(\"sweep_Nb_summary.csv\", index=False)\n",
    "\n",
    "# ==========================\n",
    "# Sweep 4: parameter samples N_k\n",
    "# ==========================\n",
    "Nk_list = [11, 21, 51, 101]  # values to test for N_k\n",
    "\n",
    "results_Nk = []\n",
    "\n",
    "for N_k in Nk_list:\n",
    "    print(f\"\\n=== Sweep N_k = {N_k} (N_i={BASE_N_i}, N_b={BASE_N_b}, N_f={BASE_N_f}) ===\")\n",
    "    rec = run_single_experiment(\n",
    "        N_i=BASE_N_i,\n",
    "        N_b=BASE_N_b,\n",
    "        N_k=N_k,\n",
    "        N_f=BASE_N_f,\n",
    "        N_val=N_val,\n",
    "        Train_epochs=Train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        k_val_eval=k_val_eval,\n",
    "        results_dir=\"sweep_Nk\",\n",
    "        seed=123\n",
    "    )\n",
    "    results_Nk.append(rec)\n",
    "\n",
    "df_Nk = pd.DataFrame([\n",
    "    {\n",
    "        \"N_i\": r[\"N_i\"], \"N_b\": r[\"N_b\"], \"N_k\": r[\"N_k\"], \"N_f\": r[\"N_f\"],\n",
    "        \"total_elapsed\": r[\"total_elapsed\"],\n",
    "        \"best_ep\": r[\"best_ep\"],\n",
    "        \"best_TL\": r[\"best_TL\"],\n",
    "        \"best_v\": r[\"best_v\"],\n",
    "        \"best_max_err\": r[\"best_max_err\"],\n",
    "        \"rel_L2\": r[\"rel_L2\"],\n",
    "        \"loss_values\": r[\"loss_values\"],\n",
    "        \"mse_v_hist\": r[\"mse_v_hist\"],\n",
    "        \"max_errors\": r[\"max_errors\"],\n",
    "        \"training_curve_path\": r[\"training_curve_path\"],\n",
    "    }\n",
    "    for r in results_Nk\n",
    "])\n",
    "\n",
    "print(\"\\nN_k sweep summary:\")\n",
    "display(df_Nk)\n",
    "\n",
    "df_Nk.to_csv(\"sweep_Nk_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1758839791644,
     "user": {
      "displayName": "Oscar Zhang",
      "userId": "08884929965206842440"
     },
     "user_tz": -60
    },
    "id": "jQWrqMPo5Apy"
   },
   "outputs": [],
   "source": [
    "# t = data['t'].flatten()[:,None] # read in t and flatten into column vector\n",
    "# x = data['x'].flatten()[:,None] # read in x and flatten into column vector\n",
    "#  # Exact represents the exact solution to the problem, from the data provided\n",
    "# Exact = np.real(data['usol']).T # Exact has structure of nt times nx\n",
    "\n",
    "# print(\"usol shape (nt, nx) = \", Exact.shape)\n",
    "\n",
    "# # We need to find all the x,t coordinate pairs in the domain\n",
    "# X, T = np.meshgrid(x,t)\n",
    "\n",
    "# # Flatten the coordinate grid into pairs of x,t coordinates\n",
    "# X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None])) # coordinates x,t\n",
    "# u_star = Exact.flatten()[:,None]   # corresponding solution value with each coordinate\n",
    "\n",
    "\n",
    "# print(\"X has shape \", X.shape, \", X_star has shape \", X_star.shape, \", u_star has shape \", u_star.shape)\n",
    "\n",
    "# # Domain bounds (-1,1)\n",
    "# lb = X_star.min(axis=0)\n",
    "# ub = X_star.max(axis=0)\n",
    "\n",
    "# print(\"Lower bounds of x,t: \", lb)\n",
    "# print(\"Upper bounds of x,t: \", ub)\n",
    "# print('')\n",
    "# print('The first few entries of X_star are:')\n",
    "# print( X_star[0:5, :] )\n",
    "\n",
    "# print('')\n",
    "# print('The first few entries of u_star are:')\n",
    "# print( u_star[0:5, :] )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
